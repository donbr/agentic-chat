# Part 3: agentic Search & Agents SDK ## [00:00:03 - 00:00:33] All right, Whiz, I heard ChatGPT was no longer just a rapper for a large longer just a rapper for a large language model, but it was in fact an language model, but it was in fact an agent. Is that right? agent. That's right. And even a multi- aent system. Can we Yeah, I think so. I think we can say Yeah, I think so. I think we can say Yeah. Yeah. All right. So there's like a lot of like All right. So there's like a lot of like aentic aentic aentic happenings going on under the hood in happenings going on under the hood in ChatGPT claude Gemini uh of course all ## [00:00:33 - 00:01:06] ChatGPT claude Gemini uh of course all of these you know your own coding agent of these you know your own coding agent and software engineering agent platforms and software engineering agent platforms we see out there but the large language we see out there but the large language pro model providers themselves are pro model providers themselves are actually really not just model labs But actually really not just model labs But agent labs now, is this fair to say? agent labs now, is this fair to say? Yeah. I mean, it's uh it's the way of Yeah. I mean, it's uh it's the way of the future. The way the wind has been the future. The way the wind has been blowing, the way the way we're going. blowing, the way the way we're going. That's right. Yeah. And we That's right. And we have a lot of agentic stuff to do the ## [00:01:06 - 00:01:39] have a lot of agentic stuff to do the rest of this series. Uh we're going to rest of this series. Uh we're going to start off today with a gentic search and start off today with a gentic search and we've got to paint a broad picture of we've got to paint a broad picture of what it means to be an agent, to be a what it means to be an agent, to be a gentic, to do search and then we've got gentic, to do search and then we've got a lot more agentic stuff coming. But a lot more agentic stuff coming. But today we lay the groundwork. Today we dig into the details. What is an agent? dig into the details. What is agentic search really? And then why do we need the OpenAI Agents SDK ## [00:01:39 - 00:02:10] why do we need the OpenAI Agents SDK in addition to or instead of just using in addition to or instead of just using the Responses API? I'm quite excited to the Responses API? I'm quite excited to get into all the details today. Um is get into all the details today. Um is there any sort of TLDDR on why OpenAI there any sort of TLDDR on why OpenAI Agents SDK is necessary for us and why Agents SDK is necessary for us and why we can't complete a proper build without we can't complete a proper build without it? why Responses API simply doesn't cut it? it. Uh yes, Responses API is dope, but it ## [00:02:10 - 00:02:44] Uh yes, Responses API is dope, but it doesn't allow us to kind of compose doesn't allow us to kind of compose together different functions and uh and together different functions and uh and pieces, right? It's like a pieces, right? It's like a one hit, right? Like you hit it, you one hit, right? Like you hit it, you get a response. It doesn't really let us get a response. It doesn't really let us build these these workflows that that build these these workflows that that you might see like deep research or or you might see like deep research or or others. Okay. So, it's an API that you others. So, it's an API that you hit it and you get a response. The hit it and you get a response. The Responses API, Responses API, right? So, when we want to use right? So, when we want to use functions, when we want to use tools, functions, when we want to use tools, when we want to use agents, when we want when we want to use agents, when we want to get more agency into our workflows or ## [00:02:44 - 00:03:14] to get more agency into our workflows or even just have more complex workflows, even just have more complex workflows, we need something a little bit more we need something a little bit more flexible. flexible. That's right. And that's where Agents SDK comes in. Fantastic. Okay. So we're going to have Fantastic. So we're going to have a wide- ranging discussion today, Wiz a wide- ranging discussion today, Wiz talking about everything from core talking about everything from core agents to agentic search to workflows to agents to agentic search to workflows to agency to functions to tools and to the agency to functions to tools and to the OpenAI Agents SDK. You've got not a OpenAI Agents SDK. You've got not a deep research application for us today, deep research application for us today, but a searching and research but a searching and research application. Yeah, absolutely. ## [00:03:14 - 00:03:46] application. Yeah, absolutely. Well, I'm excited for this one. You ready to kick it off? You know it. All right, let's get into it today. Whiz will see you back as we have the discuss will see you back as we have the discuss and we're gonna go ahead and encourage and we're gonna go ahead and encourage everybody if you've got questions along everybody if you've got questions along the way. Smash the YouTube live chat, the way. Smash the YouTube live chat, drop a comment on your viewing platform, drop a comment on your viewing platform, let us know what's not making sense to let us know what's not making sense to you and uh we'll we'll definitely get you and uh we'll we'll definitely get you included in on the conversation you included in on the conversation today. So with that, let's get into how today. So with that, let's get into how to build ChatGPT part three. This one's ## [00:03:46 - 00:04:17] to build ChatGPT part three. This one's called aentic search and the Agents SDK. This is going to be a This is going to be a wide ranging background talk that we're wide ranging background talk that we're going to set the tone of today with. We going to set the tone of today with. We need to answer the question, what is an need to answer the question, what is an agent? We need to understand what the agent? We need to understand what the foundational patterns of agentic foundational patterns of agentic behavior are for both agents and multi- behavior are for both agents and multi- aent systems. This is going to allow us aent systems. This is going to allow us to build all of the agentic capabilities ## [00:04:17 - 00:04:49] to build all of the agentic capabilities in our own ChatGPT application. We also in our own ChatGPT application. We also need to understand what the core need to understand what the core constructs are of the Agents SDK and constructs are of the Agents SDK and we'll go a little bit deeper into the we'll go a little bit deeper into the things that it can do that the responses things that it can do that the Responses API simply cannot. Whiz has a research API simply cannot. Whiz has a research bot ready for us, but we've got some bot ready for us, but we've got some agents to talk about first. from agents to talk about first. from definitions to tools to function calling definitions to tools to function calling to context engineering to workflows to to context engineering to workflows to design patterns and we will demystify ## [00:04:49 - 00:05:21] design patterns and we will demystify the terminology that is so so confusing the terminology that is so so confusing that people are out there using all the that people are out there using all the time. uh what really matters to time. uh what really matters to understand. We'll get to the bottom of understand. We'll get to the bottom of it today. So you can not just brag on it today. So you can not just brag on LinkedIn, but you can actually build LinkedIn, but you can actually build cool demos and potentially even create cool demos and potentially even create real business value for your company, real business value for your company, for your clients. Let's root ourselves for your clients. Let's root ourselves in the UI in ChatGPT. First, let's talk in the UI in ChatGPT. First, let's talk about what we're talking about. When we about what we're talking about. When we see ChatGPT, we can see ## [00:05:21 - 00:05:52] see ChatGPT, we can see we can hit the little plus sign. If we we can hit the little plus sign. If we zoom in, we can take a look here. The search The search The search doesn't even have a specific thing. It's doesn't even have a specific thing. It's just built in to when we ask. It's going to do search kind of by default. This is one of the capabilities that we're going one of the capabilities that we're going to build in today. This general web to build in today. This general web search. Now, of course, agent mode has search. Deep research has agents. We're ## [00:05:52 - 00:06:24] agents. Deep research has agents. We're not quite going to do this. We're going to focus on this higher level of agentic to focus on this higher level of agentic search, but you'll notice that we'll search, but you'll notice that we'll we'll we'll lay the groundwork for each we'll we'll lay the groundwork for each and every piece of the agents to come in and every piece of the agents to come in the rest of this series. So, let's go the rest of this series. So, let's go ahead and define agents. ahead and define agents. Agents today Agents today are best defined as simply giving the are best defined as simply giving the LLM access to tools. That's the top ## [00:06:24 - 00:06:56] LLM access to tools. That's the top level definition. A way that we can level definition. A way that we can think about this in some sort of think about this in some sort of subsequent supplementary definitions are subsequent supplementary definitions are that we we're using these to enhance that we we're using these to enhance search and retrieval. Think of this as search and retrieval. Think of this as an extension of RAG. It's a little bit an extension of RAG. It's a little bit fancier. can get a little bit more fancier. can get a little bit more up-to-date information. up-to-date information. The pattern being used that we sort of The pattern being used that we sort of alluded to in the opening here is it's alluded to in the opening here is it's not just a quick hit it get a response. not just a quick hit it get a response. We're actually going to think through ## [00:06:56 - 00:07:26] We're actually going to think through what we're going to do next. We're going what we're going to do next. We're going to be able to leverage cycles and loops to be able to leverage cycles and loops and and think about what we're going to do at think about what we're going to do at each step of the process before we do each step of the process before we do it. it. If we want to, maybe we don't need to If we want to, maybe we don't need to think, maybe we'll just take the next think, maybe we'll just take the next step. But whether we're actually step. But whether we're actually building out a process step by step building out a process step by step that's rigid or we want to add more ## [00:07:26 - 00:07:58] that's rigid or we want to add more agency to that process, we're going to agency to that process, we're going to be thinking about doing these cycles and be thinking about doing these cycles and we're going to be thinking about taking we're going to be thinking about taking actions generally after a reasoning actions generally after a reasoning step. This is kind of a meta pattern. So step. So when we define AI, when we define agents when we define AI, when we define agents at AI maker space, we want you guys to at AI maker space, we want you guys to think about this as just a system that think about this as just a system that can leverage this reasoning action can leverage this reasoning action pattern. It can leverage reasoning to ## [00:07:58 - 00:08:30] pattern. It can leverage reasoning to make dynamic decisions in an make dynamic decisions in an application. There's a lot of things application. There's a lot of things that people will say about agents that that people will say about agents that are not really related to application are not really related to application development. As AI engineers, we don't development. As AI engineers, we don't really care about those more theoretical really care about those more theoretical ideas. Not today. Not until we're ideas. Not until we're building apps and building products with building apps and building products with those ideas. And so when we think about those ideas. And so when we think about agents as kind of taking RAG to the next agents as kind of taking RAG to the next level, we want to remember that RAG was ## [00:08:30 - 00:09:03] level, we want to remember that RAG was all about retrieval. If we do it well, all about retrieval. If we do it well, our generation is better. When we give our generation is better. When we give the LM access to new knowledge it wasn't the LM access to new knowledge it wasn't trained on through dense vector trained on through dense vector retrieval, putting that in context retrieval, putting that in context through this retriever and generator through this retriever and generator setup we can get better answers. Now setup we can get better answers. Now agents agents agents they come into play during retrieval. Uh they come into play during retrieval. Uh really we're going to do some additional really we're going to do some additional search and we're going to go find some ## [00:09:03 - 00:09:36] search and we're going to go find some data that isn't sitting in a vector data that isn't sitting in a vector store, but maybe it's just somewhere out store, but maybe it's just somewhere out on the internet or maybe it's just more on the internet or maybe it's just more flexibly connected to exactly what our flexibly connected to exactly what our application is. uh perhaps we have a application is. uh perhaps we have a very very large set of possible places very very large set of possible places that we can look for data and agents that we can look for data and agents might help us to do just that. So we can might help us to do just that. So we can sort of imagine that an agent is going sort of imagine that an agent is going to be able to look at things like to be able to look at things like metadata, look at things that we don't ## [00:09:36 - 00:10:07] metadata, look at things that we don't have in our databases. And so we're have in our databases. And so we're we're able to sort of take RAG to the we're able to sort of take RAG to the next level very simply with agents. next level very simply with agents. The important idea here with agents that The important idea here with agents that we really want to we really want to be able to talk about intelligently be able to talk about intelligently is tools. Because everybody is talking is tools. Because everybody is talking about tools about tools and agents when you give them access to ## [00:10:07 - 00:10:38] agents when you give them access to tools they can be more useful. They can tools they can be more useful. They can solve more problems. solve more problems. This very very simple idea of the LLM This very very simple idea of the LLM given access to tools literally giving given access to tools literally giving it access to tools creates it access to tools creates an agent. So the LM becomes an agent an agent. So the LM becomes an agent when it gets access to tools. So we're when it gets access to tools. So we're not just going and getting the answer. We're going to the LM. It's thinking, do ## [00:10:38 - 00:11:09] We're going to the LM. It's thinking, do I need to go find some additional I need to go find some additional information and then maybe I'll get an information and then maybe I'll get an answer? So we can we can sort of think answer? So we can we can sort of think of the LM as a superhero. And we're of the LM as a superhero. And we're going to pick out tools from our going to pick out tools from our superhero tool belt as necessary. superhero tool belt as necessary. We can visualize this very simply as We can visualize this very simply as well. Similar to the way we talked about well. Similar to the way we talked about RAG, we can ask a question, RAG, we can ask a question, we can go to our agent, to our LLM, and we can go to our agent, to our LLM, and our LLM can sort of decide, do I do I our LLM can sort of decide, do I do I need to take an action? ## [00:11:09 - 00:11:39] need to take an action? I've reasoned I need to take an action. So, what should that action be? Well, whatever it is, I'm going to feed the whatever it is, I'm going to feed the result of it back in to context before I result of it back in to context before I produce my final answer. Now, those produce my final answer. Now, those actions are likely going to be actions are likely going to be associated with tools that we can call associated with tools that we can call or functions that we can call more or functions that we can call more generally. And when we put it back into generally. And when we put it back into context, we're sort of maintaining this context, we're sort of maintaining this this kind of conversation thread that ## [00:11:39 - 00:12:10] this kind of conversation thread that includes our observations and each step includes our observations and each step of reasoning that we take. of reasoning that we take. And so, we're giving the LM access to And so, we're giving the LM access to tools while sort of enhancing retrieval. tools while sort of enhancing retrieval. And as we talked about in session one, And as we talked about in session one, this big idea of using the this big idea of using the either Chat Completions API or responses either Chat Completions API or Responses API or assistance API API or assistance API was that we can make a request, we can was that we can make a request, we can get a response. Now this is also true ## [00:12:10 - 00:12:41] get a response. Now this is also true with something like tool calling as we with something like tool calling as we discussed. Now what's interesting here discussed. Now what's interesting here is that if we look at the tool that we is that if we look at the tool that we define and then we call here call right define and then we call here call right here we're then going and getting a here we're then going and getting a response. response. Okay, great. So this is kind of related Okay, great. So this is kind of related to agents to agents to agents in a very straightforward way. Let's in a very straightforward way. Let's connect this even further. Let's talk about the reasoning action pattern ## [00:12:41 - 00:13:16] about the reasoning action pattern itself and function calling. Now, so itself and function calling. Now, so we've got this setup of ask a question we've got this setup of ask a question to the agent. The agent takes some to the agent. The agent takes some action. It gets some observation. Uh but action. Uh but what's happening right here exactly? Well, we're we're kind of going through Well, we're we're kind of going through this reasoning and action pattern. We're this reasoning and action pattern. We're thinking through what should we do next? And then we're acting. And this is where this third piece comes And this is where this third piece comes in. this react pattern, this ## [00:13:16 - 00:13:48] in. this react pattern, this reasoning and action, picking up the reasoning and action, picking up the right tool for the right job pattern. right tool for the right job pattern. You see, agents are a pattern. They're not this specific thing. They're one way to think about them that we have one way to think about them that we have locked in so far is this tool calling in locked in so far is this tool calling in a loop kind of pattern. But more a loop kind of pattern. But more generally, we can think of this as the generally, we can think of this as the react pattern, the reasoning and action react pattern, the reasoning and action pattern. This is from the React paper on ## [00:13:48 - 00:14:18] pattern. This is from the React paper on synergizing reasoning and acting in synergizing reasoning and acting in language models. This is an OG from language models. This is an OG from October 2022. October 2022. And we can use reasoning traces as the And we can use reasoning traces as the paper tells us to help the model induce, paper tells us to help the model induce, track and update action plans. track and update action plans. planning very essential sort of design planning very essential sort of design pattern or agentic design pattern that pattern or agentic design pattern that we'll see uh we we we start to see we'll see uh we we we start to see almost really everywhere in sufficiently ## [00:14:18 - 00:14:49] almost really everywhere in sufficiently complex systems today. And those actions complex systems today. And those actions allow us to go get info from the allow us to go get info from the internet, from external sources of internet, from external sources of information, from really anywhere. information, from really anywhere. And so also interestingly, And so also interestingly, this action piece simply uses a this action piece simply uses a fine-tuned LLM. fine-tuned LLM. And it does this sort of tool or And it does this sort of tool or function call by calling this fine-tuned function call by calling this fine-tuned LLM that's very good at this. You see ## [00:14:49 - 00:15:21] LLM that's very good at this. You see this reasoning and action pattern. If we sort of connect these two things sort of connect these two things together together together into one step, that step is simply into one step, that step is simply function calling. function calling. Function calling Function calling is literally is literally combining reasoning and action into one combining reasoning and action into one step. step. Function calling also is a tool Function calling also is a tool and that's why we can sort of talk about ## [00:15:21 - 00:15:53] and that's why we can sort of talk about the very baseline of agents being giving the very baseline of agents being giving the LLM access to tools. Now, you might the LLM access to tools. Now, you might remember from the first session we remember from the first session we talked about together, we talked about talked about together, we talked about the OpenAI function calling API from the OpenAI function calling API from June 2023. June 2023. And this was released a long, long time And this was released a long, long time ago at this point. And you know, now you ago at this point. And you know, now you know now we can have the model know now we can have the model intelligently choose to output a JSON intelligently choose to output a JSON object. These models have been object. These models have been fine-tuned to detect both when a fine-tuned to detect both when a function needs to be called and to ## [00:15:53 - 00:16:25] function needs to be called and to respond with JSON that adheres to the respond with JSON that adheres to the function signature. So remember the big function signature. So remember the big idea is the request response setup. Tool idea is the request response setup. Tool calling gives us the tool and gives us calling gives us the tool and gives us the calling and the response. But we the calling and the response. But we could also sort of replace this idea of could also sort of replace this idea of just calling it tool calling with like just calling it tool calling with like function calling because what happens is function calling because what happens is we actually have to execute this we actually have to execute this function code and it could be just a function code and it could be just a tool that we're executing the function tool that we're executing the function code for of course and so so we kind of ## [00:16:25 - 00:16:55] code for of course and so so we kind of start to blur the line here between tool start to blur the line here between tool and function. So first discussion of the and function. So first discussion of the day here whiz um I'd love your feedback day here whiz um I'd love your feedback on this. So is it tool calling or is it on this. So is it tool calling or is it function calling? First off, function calling? First off, uh you know this is an interesting uh you know this is an interesting question because uh tools are interacted question because uh tools are interacted with through functions. So it's it's I with through functions. So it's it's I mean they mean the same thing. mean they mean the same thing. Okay. So is one like a superset of the ## [00:16:56 - 00:17:27] Okay. So is one like a superset of the other or no? other or no? I mean like function calling, tool I mean like function calling, tool calling. calling. Okay. Same same. you know it's uh they they Same same. you know it's uh they they are uh two different ways to say the are uh two different ways to say the same thing. So let's say I have a tool same thing. So let's say I have a tool and it just helps me search the web. SER and it just helps me search the web. SER API or any other API that makes me surf API or any other API that makes me surf the search the web tavally. Uh if I use the search the web tavally. Uh if I use that tool, am I doing a gentic search? Uh if you're Yes, ## [00:17:27 - 00:17:59] Uh if you're Yes, that's it. that's it. Yes, Yes, Yes, that's a gentic search. that's a gentic search. That's googling it as an AI is a gentic That's googling it as an AI is a gentic search. As long as you are using the search. As long as you are using the agent to determine the queries and then agent to determine the queries and then you're determining the output uh based you're determining the output uh based on the fetched results and then you're on the fetched results and then you're deciding whether or not to continue deciding whether or not to continue searching or being done searching. Uh searching or being done searching. Uh hey, that's a search, you know. So, it's basically like human search but So, it's basically like human search but automated. ## [00:17:59 - 00:18:31] automated. That's definitely a way to say that. Yeah. Okay. All right. All Yeah. Yeah. Okay. All right. It's like right. It's like it's like it's like human search but an it's like it's like human search but an agent's doing it. agent's doing it. Yeah. But like AI. That's right. All right. That's dope. Um Okay. Well, I All right. Well, I guess I guess that's pretty simple then. So, So, So, it's not that bad. it's not that bad. I guess that's all there is to it. Okay. We'll keep it moving then, Wiz. Thanks for your insights. for your insights. Okay. So, we'll get into how does this Okay. So, we'll get into how does this come together into all the things we've come together into all the things we've discussed so far in the series. Well, discussed so far in the series. Well, this is where context engineering comes ## [00:18:32 - 00:19:02] this is where context engineering comes up. Remember, an agent is simply a up. Remember, an agent is simply a system that can leverage or emulate system that can leverage or emulate reasoning to make dynamic decisions. reasoning to make dynamic decisions. It's doing that decision-making thing It's doing that decision-making thing for us. It's got agency, for us. It's got agency, has access to tools. We can enhance has access to tools. We can enhance retrieval. It's the React pattern. And retrieval. And remember, RAG was giving the LM access remember, RAG was giving the LM access to new knowledge, which of course tools to new knowledge, which of course tools can help us find as well. and it was can help us find as well. and it was doing retrieval, putting it in context. And of course, prompt engineering, as we ## [00:19:02 - 00:19:33] And of course, prompt engineering, as we learned in session one of the series, is learned in session one of the series, is just giving ELM instructions in context. just giving ELM instructions in context. And so, you know, we kind of also threw And so, you know, we kind of also threw out in that session that prompt out in that session that prompt engineering is now kind of subsumed by engineering is now kind of subsumed by context engineering. And so this this context engineering. And so this this larger context engineering piece larger context engineering piece includes all of prompt engineering. In includes all of prompt engineering. In fact, it includes all of RAG as well. Now, if we look a little bit closer at Now, if we look a little bit closer at this, and we can see lots of different ## [00:19:33 - 00:20:03] this, and we can see lots of different types of ways people have visualized types of ways people have visualized this in the past. It's like I don't see this in the past. It's like I don't see agents exactly, but I do see tools. agents exactly, but I do see tools. I also see some memory and state and I also see some memory and state and history here. That's pretty interesting. history here. But I see tools. And so, you know, we've But I see tools. And so, you know, we've often uh seen people talk about context often uh seen people talk about context engineering in this way. Instructions, engineering in this way. Instructions, knowledge, and tools. I think it's fair knowledge, and tools. I think it's fair to say we can call this kind of prompt ## [00:20:03 - 00:20:35] to say we can call this kind of prompt engineering RAG and agents. We're we're engineering RAG and agents. We're we're hearing things about context hearing things about context engineering. You know, it's the delicate engineering. You know, it's the delicate art and science of filling the context art and science of filling the context window with just the right info for the window with just the right info for the next step. Context engineering, some next step. Context engineering, some say, is the number one job of building say, is the number one job of building AI agents. AI agents. Okay, so I've got a clarifying question. Whiz, maybe you can help us out again Whiz, maybe you can help us out again here. So here. So are agents actually part of context ## [00:20:35 - 00:21:07] are agents actually part of context engineering or is context engineering engineering or is context engineering just sort of part of building agents? just sort of part of building agents? So uh context engineering is the idea of So uh context engineering is the idea of uh maneuvering and smooing context uh maneuvering and smooing context around in order to uh achieve some goal. around in order to uh achieve some goal. So in some sense agents are systems by So in some sense agents are systems by which we do context engineering. which we do context engineering. So yes they're a part of it. Are they ## [00:21:07 - 00:21:37] So yes they're a part of it. Are they like like like in the circle of context engineering by in the circle of context engineering by themselves? themselves? They're no they leverage all the things They're no they leverage all the things in the circle right so it's a it's a in the circle right so it's a it's a it's a different kind of uh a it's a different kind of uh a relationship to context engineering so relationship to context engineering so like you know context engineering is not like you know context engineering is not agent but agent does context engineering agent but agent does context engineering yeah yeah yeah well and because the LLM yeah yeah yeah well and because the LLM is like the agent and so is like the agent and so holding everything in context who's ## [00:21:37 - 00:22:07] holding everything in context who's doing it the LLM if it's got agency uh doing it the LLM if it's got agency uh it's an agent And so like in some sense, it's an agent And so like in some sense, yeah, agent kind of sits above. yeah, agent kind of sits above. That's right. Interesting. Agent agent sits above above all. But but then what about app even above But but then what about app even above that and we have agents talking to each that and we have agents talking to each other, but context covers both of those. other, but context covers both of those. I don't know. It's it's hard to I don't know. It's it's hard to visualize. Maybe this is part of the visualize. Maybe this is part of the issue why these terms keep changing. ## [00:22:07 - 00:22:37] issue why these terms keep changing. It's definitely It's definitely hard to It's definitely It's definitely hard to visualize. I mean, but the idea is visualize. I mean, but the idea is that it's actually, you know, you can that it's actually, you know, you can kind of think of like agents are systems kind of think of like agents are systems that that do the context engineering. that that do the context engineering. And so when I have when I am thinking And so when I have when I am thinking about an agent, I'm thinking how am I about an agent, I'm thinking how am I using this to to do context engineering, using this to to do context engineering, right? Uh as opposed to like I'm doing right? Uh as opposed to like I'm doing context engineering, therefore I want to context engineering, therefore I want to do agent. ## [00:22:38 - 00:23:09] Yeah. Okay. So, uh, maybe we can just Okay. So, uh, maybe we can just both reflect on this incredible quote both reflect on this incredible quote from, uh, the man, the myth, the legend, from, uh, the man, the myth, the legend, Dex Hory, who coined the term context Dex Hory, who coined the term context engineering. engineering. Everything that makes agents good Everything that makes agents good is context engineering. is context engineering. That feels pretty good. That feels good. There you go. I love that. All right. Let's keep it rolling. I love All right. I love that, too. Okay. All right. We're that, too. We're getting somewhere here. So we can also ## [00:23:09 - 00:23:41] getting somewhere here. So we can also learn from what some of the big model learn from what some of the big model providers agent labs are are putting out providers agent labs are are putting out what they're telling us, what they teach what they're telling us, what they teach us from the systems they've built. For us from the systems they've built. For instance, Anthropic building their instance, Anthropic building their multi- aent research system. They say multi- aent research system. They say things like, you know, agents often things like, you know, agents often engage in conversations spanning engage in conversations spanning hundreds of turns. We need very careful hundreds of turns. We need very careful context management here. Careful context management here. Careful conversation management. And this is conversation management. And this is again just visualizing only one agent again just visualizing only one agent having a conversation with ## [00:23:41 - 00:24:14] having a conversation with the environment so to speak of tools and the environment so to speak of tools and of questions and of context that it of questions and of context that it lives in. lives in. Okay. So let's talk about Okay. So let's talk about agency agency agency and workflows. Let's talk about the and workflows. Let's talk about the complexity of workflows. And while complexity of workflows. And while agents enable a lot of very complex agents enable a lot of very complex things, and this is things, and this is essentially getting back to the science essentially getting back to the science of complexity itself, that by very ## [00:24:14 - 00:24:44] of complexity itself, that by very simple rules and very simple tools, very simple rules and very simple tools, very simple function calls, we could imagine simple function calls, we could imagine producing fairly producing fairly complicated, even emergent, complex complicated, even emergent, complex behavior. This is something that's been behavior. This is something that's been wellstied by people like Steven Wolfram wellstied by people like Steven Wolfram for many many decades. This science of for many many decades. This science of complexity complexity complexity and it's true that with very simple and it's true that with very simple rules we can produce incredible rules we can produce incredible behavior. At the same time though if we behavior. At the same time though if we want to create real ROI for our ## [00:24:44 - 00:25:16] want to create real ROI for our companies Anthropic and others are companies Anthropic and others are constantly reminding us like we need to constantly reminding us like we need to find the simplest possible solution. We find the simplest possible solution. We don't want additional complexity if we don't want additional complexity if we don't need complexity. But when do we don't need complexity. But when do we need complexity exactly? Well, need complexity exactly? Well, we need complexity when we need an LLM we need complexity when we need an LLM to do that reasoning in the midst of a to do that reasoning in the midst of a workflow. And that's where we don't want workflow. And that's where we don't want it to be rigid. We want to build in some ## [00:25:16 - 00:25:47] it to be rigid. We want to build in some flexibility. We want to bake in and flexibility. We want to bake in and automate some of that flexibility automate some of that flexibility because workflows and agency because workflows and agency workflows and agents workflows and agents rather exist on a spectrum and agentic rather exist on a spectrum and agentic systems themselves will have some level systems themselves will have some level of workflow that is sort of rigid of workflow that is sort of rigid step-by-step process and some level of step-by-step process and some level of agent some level of agency. agent some level of agency. And this can be visualized in a lot of And this can be visualized in a lot of sort of different ways. But you know at ## [00:25:47 - 00:26:18] sort of different ways. But you know at every level of agent there's a level of every level of agent there's a level of workflow and at every level of workflow workflow and at every level of workflow there's a level of agent. there's a level of agent. So we can kind of consider how much So we can kind of consider how much agency do we need? And so the agency do we need? And so the question we should all ask before we question we should all ask before we build an agent is, do I really need build an agent is, do I really need dynamic reasoning to solve the task or dynamic reasoning to solve the task or the problem I'm trying to solve more the problem I'm trying to solve more effectively than a rigid workflow could? effectively than a rigid workflow could? And this is where you're going to be ## [00:26:18 - 00:26:50] And this is where you're going to be able to, you know, really want to able to, you know, really want to clearly answer yes. Now, it gets a clearly answer yes. Now, it gets a little bit hairy here because if the little bit hairy here because if the workflow, workflow, workflow, let's say, does a tool call and a search let's say, does a tool call and a search every time, is that still an agent? every time, is that still an agent? Well, yes, there still is agency in Well, yes, there still is agency in doing that search. Uh, let's dig a doing that search. Uh, let's dig a little bit deeper by getting into multi- little bit deeper by getting into multi- aent systems. aent systems. And I want to just root ourselves in a ## [00:26:50 - 00:27:21] And I want to just root ourselves in a really interesting definition from the really interesting definition from the classic text classic text artificial intelligence a modern artificial intelligence a modern approach. approach. AI itself is defined in this textbook as AI itself is defined in this textbook as the study and design of rational the study and design of rational agents. agents. And as we've sort of demonstrated today And as we've sort of demonstrated today so far, we're talking about agents, but so far, we're talking about agents, but really we're kind of talking about really we're kind of talking about agentic reasoning because agents are a ## [00:27:21 - 00:27:52] agentic reasoning because agents are a pattern. They're not a specific thing. pattern. They're this kind of reasoning and They're this kind of reasoning and action pattern. We action pattern. We ask the agent a question and it is going ask the agent a question and it is going to have agency to go through and do a to have agency to go through and do a lot of stuff before it gets us the final lot of stuff before it gets us the final answer. It's got access to tools. It's answer. It's going to enhance our ability to do going to enhance our ability to do search and retrieval. And it's going to search and retrieval. And it's going to go through this loop go through this loop as we've defined. It's going to leverage as we've defined. It's going to leverage reasoning. ## [00:27:52 - 00:28:24] reasoning. And if we extend this definition of And if we extend this definition of agent or a gentic system to multi- aents agent or a gentic system to multi- aents or a multi- aent system, we're just or a multi- aent system, we're just going to say that this is a system that going to say that this is a system that can leverage reasoning from multiple can leverage reasoning from multiple independent agents to again make dynamic independent agents to again make dynamic decisions in an application flow. And decisions in an application flow. And the question comes almost immediately, the question comes almost immediately, well, why would I need more than one well, why would I need more than one agent? agent? And if we extend again our critical ## [00:28:24 - 00:28:54] And if we extend again our critical question before we build an agent, we question before we build an agent, we should ask, do I really need dynamic should ask, do I really need dynamic reasoning to solve the task more reasoning to solve the task more effectively than a rigid workflow could? effectively than a rigid workflow could? Before I build a multi- aent system, I Before I build a multi- aent system, I might ask, do I really need several might ask, do I really need several specialized specialized dynamic reasoning machines dynamic reasoning machines collaborating collaborating to solve the task more effectively than to solve the task more effectively than a single agent could? a single agent could? Another way that we can easily think ## [00:28:54 - 00:29:26] Another way that we can easily think about how to choose what do I really about how to choose what do I really need here is before I build an agent, I need here is before I build an agent, I should probably ask like do I have too should probably ask like do I have too many things that indicate I need more many things that indicate I need more agency? if else if else if else if else agency? if else if else if else if else if else if else if there's just a ton of if else if else if there's just a ton of potential paths maybe I should think potential paths maybe I should think about putting an agent in uh you know about putting an agent in uh you know smart head an LLM with agency in that smart head an LLM with agency in that spot if I have ## [00:29:26 - 00:29:59] spot if I have an agentic system and I still find an agentic system and I still find myself with too many of these if else if myself with too many of these if else if else if else if else if else if paths else if else if else if else if paths maybe I put another head and I let it maybe I put another head and I let it kind of decide for me. You see these kind of decide for me. You see these multi- aent systems are really good if multi- aent systems are really good if we want to kind of separate we want to kind of separate responsibilities, responsibilities, separate decision- making, separate or separate decision- making, separate or even group tools together. So that would even group tools together. So that would be a specific, you know, type of person, ## [00:29:59 - 00:30:31] be a specific, you know, type of person, type of AI that kind of uses that set of type of AI that kind of uses that set of tools very well. This is how we sort of tools very well. This is how we sort of talk about jobs as humans. We can talk about jobs as humans. We can separate what their sort of roles are, separate what their sort of roles are, what their context is, just like classic what their context is, just like classic prompt engineering best practices and prompt engineering best practices and it makes for a lot of really easy to and it makes for a lot of really easy to gro conceptual models. Essentially we gro conceptual models. Essentially we can separate functions can separate functions uh tools uh tools uh tools uh really kind of both and different ## [00:30:31 - 00:31:03] uh really kind of both and different kinds of functions kinds of functions and different kinds of tools and different kinds of tools because function calling combines react because function calling combines react into a single step. What we see in into a single step. What we see in multi- aent systems is we see that this multi- aent systems is we see that this sort of react pattern, this this sort of react pattern, this this function calling pattern is happening function calling pattern is happening literally all the way down. And so literally all the way down. And so there's there's a really interesting there's there's a really interesting kind of terminology issue that we run kind of terminology issue that we run into into into when we think about tools versus agents ## [00:31:03 - 00:31:12] when we think about tools versus agents or versus multi- aent systems. or versus multi- aent systems. You see, it's often difficult to You see, it's often difficult to distinguish between tools, ## [00:43:14 - 00:43:44] difficult to distinguish between tools, single tool agents, and agent teams. single tool agents and agent teams and agent teams because because because we can call just a tool an agent or we we can call just a tool an agent or we can refer to a single tool agent as just can refer to a single tool agent as just a tool. a tool. Moreover, Moreover, Moreover, when we look at an agent that has access when we look at an agent that has access to tools, to tools, to tools, if we consider each tool as its own if we consider each tool as its own agent, then we can quickly be looking at agent, then we can quickly be looking at a multi- aent system. a multi- aent system. And so, Whiz, I've got a simple question And so, Whiz, I've got a simple question I'd love for you to help help us answer I'd love for you to help help us answer here. Like, so is an agent with two here. Like, so is an agent with two tools a multi- aent system or is just an tools a multi- aent system or is just an agent with two tools? agent with two tools? That's an agent with two tools. Yeah. So, how do we how do we sort of Yeah. So, how do we how do we sort of decide where the line is here? decide where the line is here? Uh, well, it's like uh does an agent Uh, well, it's like uh does an agent by itself by itself by itself make a multi- aent system? No. Does more make a multi- aent system? Does more than one agent working together than one agent working together make a multi- aent system? I mean, I make a multi- aent system? I mean, I hope so. You know, and there are a hope so. You know, and there are a number of ways we can achieve this. number of ways we can achieve this. There's multi- aent as in uh multiple There's multi- aent as in uh multiple different agents working on a task different agents working on a task together. There's also multi-agent as in together. There's also multi-agent as in one system that is comprised of multiple one system that is comprised of multiple agents. So there's a you know it's not agents. So there's a you know it's not like the sky's is the limit. The sky's like the sky's is the limit. The sky's is definitely not the limit. But uh you know it it it makes sense that there is know it it it makes sense that there is this idea that a multi- aent system is a this idea that a multi- aent system is a system that has more than one agent in system that has more than one agent in the in the workflow at some point. So the in the workflow at some point. So this is like where this where this gets this is like where this where this gets a little bit tricky, right? Is what if a little bit tricky, right? Is what if we have two tools and those tools are we have two tools and those tools are agents, right? Then yes, it's a multi- agents, right? Then yes, it's a multi- aent system because tool does not imply aent system because tool does not imply uh you know that it's a uh that it's uh you know that it's a uh that it's just a a function that executes a single just a a function that executes a single task like you know Python function. A task like you know Python function. A function can also be used to invoke an function can also be used to invoke an agent. Uh, and so suddenly we're, you agent. Uh, and so suddenly we're, you know, we're we're agenting it it all up. know, we're we're agenting it it all up. And I'm struck by how some tasks, even And I'm struck by how some tasks, even if it's just if it's just a tool that completes the task or a a tool that completes the task or a function that completes the task, some function that completes the task, some tasks require more agency than others. tasks require more agency than others. For instance, web search is like For instance, web search is like it it's like it's like it's not going to it it's like it's like it's not going to be rigid. be rigid. the uh the results of your web the uh the results of your web search, you know, um every time. It's search, you know, um every time. It's sort of a fundamentally more agentic sort of a fundamentally more agentic task to do than simply, you know, 2* 2, task to do than simply, you know, 2* 2, the simplest function you can think of. the simplest function you can think of. And you know, it's like uh it's like And you know, it's like uh it's like anything that sort of doesn't have a a anything that sort of doesn't have a a truly correct, you know, answer that you truly correct, you know, answer that you can verify with can verify with classic ML style accuracy. You know, classic ML style accuracy. You know, you've got some agency. You got some uh you've got some agency. You got some uh wiggle room in there. And so wiggle room in there. And so that's right. that's right. Yeah. You've got some agenty things going on. It's very It's getting agentic up in It's very It's getting agentic up in here today. here today. It's getting pretty agentic. and like this is something that's like this is something that's interesting beyond just like obviously interesting beyond just like obviously it's it's kind of a meme to to think it's it's kind of a meme to to think about and do the thought exercise and about and do the thought exercise and you know where is it? But it's it's you know where is it? But it's it's actually like a really important actually like a really important distinction because you know there's distinction because you know there's this world that people are like oh well this world that people are like oh well you should not build multi- aent systems you should not build multi- aent systems or you should x y and zed. The reality or you should x y and zed. The reality is is that you know in a vacuum that it is is that you know in a vacuum that it it doesn't mean anything to say that it doesn't mean anything to say that right like it doesn't mean anything to right like it doesn't mean anything to say say say uh you shouldn't build uh you shouldn't build uh multi- aent systems right like what do multi- aent systems right like what do you mean by multi- aent systems? you mean by multi- aent systems? You shouldn't build like multiworkflow shouldn't build like multiworkflow systems. you shouldn't be, you know, systems. you shouldn't be, you know, like that's the it's a real question in like that's the it's a real question in terms of how you approach and how you terms of how you approach and how you ingest the wisdom from the field as it ingest the wisdom from the field as it relates to, you know, what is a multi- relates to, you know, what is a multi- aent versus just agent versus tools aent versus just agent versus tools versus, you know, it's uh versus, you know, it's uh Yeah. And like an LLM itself, just if Yeah. And like an LLM itself, just if you give it a tool, it's an agent, but you give it a tool, it's an agent, but also like the fact that it's not also like the fact that it's not deterministic out of the box kind of deterministic out of the box kind of gives it some agency, you know? Um, and gives it some agency, you know? Um, and so like so like so like that's the word on the street, you know, that's the word on the street, you know, and uh, and uh, and uh, well, like a simple React agent, right? well, like a simple React agent, right? All all it does is it reasons and then All all it does is it reasons and then it takes action. it takes action. All all it all it is is the LLM decides All all it all it is is the LLM decides whether or not to call a tool or not whether or not to call a tool or not call a tool. And that's like the call a tool. And that's like the canonical agent, right? That's like the OG agent. OG agent. That's all it's doing. There's nothing That's all it's doing. There's nothing special. There's nothing fancy. It's special. It's just I I have uh I have received a just I I have uh I have received a request. I have access to some tool. request. Should I use tool for request or not? You know, and it's like that that's the You know, and it's like that that's the atomic agent at at some point and atomic agent at at some point and everything else is just a everything else is just a you know the complexity. you know the complexity. Oh, the atomic agent. I like that. The complexity expands rapidly. That's right. right. Well, yeah. As soon as you get beyond Well, yeah. As soon as you get beyond one atom, one atom, one atom, you know, you know, you know, it's just hard to track anymore. Okay. it's just hard to track anymore. Uh, fantastic physics connection there Uh, fantastic physics connection there at the end. Let's keep it moving. Whiz, at the end. Whiz, let's get into let's get into this higher level of agentic design and this higher level of agentic design and agentic systems. Now, there's a lot of agentic systems. Now, there's a lot of ways that you'll hear people talk about ways that you'll hear people talk about this from cognitive architectures. This this from cognitive architectures. This is something often talked about by is something often talked about by Harrison Chase at Lang Chain. Harrison Chase at Lang Chain. and And this same idea of sort of levels of this same idea of sort of levels of agency can be found uh you know being agency can be found uh you know being put out by teams like Hugging Face. put out by teams like Hugging Face. This kind of again this idea of This kind of again this idea of workflows workflows workflows versus agency is kind of important to versus agency is kind of important to keep in mind because we can sort of keep in mind because we can sort of start to separate some of these even start to separate some of these even single agent patterns into workflows as single agent patterns into workflows as people like Phil Schmidt have done people like Phil Schmidt have done like thinking about routing or like thinking about routing or parallelization as more of a parallelization as more of a workflow-based approach with less agency workflow-based approach with less agency whereas you know something that's truly whereas you know something that's truly agent IC is more like tool use and agent IC is more like tool use and function calling or planning or using function calling or planning or using the LM as a judge to really reflect on the LM as a judge to really reflect on its answers and produce a better one to its answers and produce a better one to sort of loop through and reason through sort of loop through and reason through what to do next. And we can sort of, you what to do next. And we can sort of, you know, broadly put multi-agent patterns know, broadly put multi-agent patterns into kind of things that have into kind of things that have supervisors and things that don't. And, supervisors and things that don't. And, you know, there there's a lot of you know, there there's a lot of different opinionated views on this. So different opinionated views on this. So if you look in Langraph's docs for if you look in Langraph's docs for instance they'll talk about multi- aent instance they'll talk about multi- aent collaboration collaboration supervisors supervisors or even hierarchical teams. If you go or even hierarchical teams. If you go and you watch some of Dr. Andrew Ing's and you watch some of Dr. Andrew Ing's talks you might see sort of four talks you might see sort of four categories put forth reflection tool use categories put forth reflection tool use planning and multi-agent collaboration. planning and multi-agent collaboration. I tried to sort of make a more I tried to sort of make a more exhaustive list here and we we can kind exhaustive list here and we we can kind of think through while it certainly of think through while it certainly might not be fully comprehensive, we can might not be fully comprehensive, we can think through all of the possibilities think through all of the possibilities for single agents to be routers uh to be for single agents to be routers uh to be tools using the react loop to write tools using the react loop to write plans to you know plan then act. It's plans to you know plan then act. It's something that is often used in deep something that is often used in deep research systems to reflect or research systems to reflect or self-critique to evaluate and optimize self-critique to evaluate and optimize to kind of use that LLM as a judge to uh to kind of use that LLM as a judge to uh look across different look across different inference outputs and choose the best inference outputs and choose the best one by committee to to think about one by committee to to think about different types of memory patterns and different types of memory patterns and really tracking and managing state and really tracking and managing state is part of again managing context. We is part of again managing context. We saw long-term and short-term memory and saw long-term and short-term memory and state discussed in those context and state discussed in those context engineering bubbles. You think about engineering bubbles. You think about parallelization, which is often, you parallelization, which is often, you know, something that we leverage in know, something that we leverage in these multi- aent systems that are these multi- aent systems that are popular today like deep research. But popular today like deep research. But really that could just be splitting a really that could just be splitting a single task into multiple subtasks. That single task into multiple subtasks. That could be the planning or it could be could be the planning or it could be actually sending multiple agents out to actually sending multiple agents out to do different things, putting a human in do different things, putting a human in the loop or or even having tool required the loop or or even having tool required specific guard rails to constrain specific guard rails to constrain specific things. Uh for instance, specific things. Uh for instance, imagine you want to give someone a imagine you want to give someone a refund automatically. That certainly refund automatically. That certainly should be something with some rails on should be something with some rails on it if a human isn't in the loop. it if a human isn't in the loop. Multi-agent systems go another level up. We can use supervisors. We can we can We can use supervisors. We can we can think about handoffs between agents as think about handoffs between agents as tools. And we'll see this is indeed how tools. And we'll see this is indeed how we think about this in the OpenAI we think about this in the OpenAI Agents SDK. Agents SDK. Hierarchical teams could be know teams Hierarchical teams could be know teams of teams. So the supervisor has a of teams. So the supervisor has a supervisor. We can think of this network supervisor. We can think of this network of free graphs and of swarms. Think of of free graphs and of swarms. Think of you know debating and collaborating. We could think of roleplaying up, you know, could think of roleplaying up, you know, sort of playing specific job title roles sort of playing specific job title roles to sort of have discussions and really to sort of have discussions and really hash things out. And we've covered hash things out. And we've covered mixture of agents on this channel before mixture of agents on this channel before where you have different LLMs getting where you have different LLMs getting responses and combining them. There's responses and combining them. There's also sort of very specific things like also sort of very specific things like deep research loops and coding agent deep research loops and coding agent loops including autonomous software loops including autonomous software engineers that we see today. Importantly engineers that we see today. Importantly though, just to root ourselves, you though, just to root ourselves, you know, our user doesn't really care what know, our user doesn't really care what patterns we use. They just want our app patterns we use. They just want our app to produce a great output for them. And to produce a great output for them. And so really, you know, making sure you so really, you know, making sure you consider that you stick with that. It's consider that you stick with that. It's always going to be of paramount always going to be of paramount importance. It's your job to figure out importance. It's your job to figure out what's bad, what's good, what's great. what's bad, what's good, what's great. And so as we think about leveraging And so as we think about leveraging different agentic patterns, let's think different agentic patterns, let's think about how we can do this using the about how we can do this using the Agents SDK. The Agents SDK is Agents SDK. The Agents SDK is OpenAI's agent framework. It's for OpenAI's agent framework. It's for orchestrating multi-agent workflows. Great. And it was built off of the back Great. And it was built off of the back of Swarm, which was their release in of Swarm, which was their release in October 2024 that has now been replaced October 2024 that has now been replaced by the OpenAI Agents SDK. It's got two by the OpenAI Agents SDK. It's got two key constructs. We need to understand key constructs. We need to understand routines routines routines and handoffs. and handoffs. The notion of a routine, I mean, you can The notion of a routine, I mean, you can imagine what a routine is. We all wake imagine what a routine is. We all wake up every morning. up every morning. While it says it's not sort of strictly While it says it's not sort of strictly defined, it can sort of mean a set of defined, it can sort of mean a set of steps. And in so far as we do have a steps. And in so far as we do have a definition, we can imagine those steps definition, we can imagine those steps are instructions. They're prompts. are instructions. And they're also the tools necessary to And they're also the tools necessary to complete those steps. The routine is a complete those steps. The routine is a set of instructions with access to set of instructions with access to tools. How very agentic. tools. And a handoff is an agent or a routine And a handoff is an agent or a routine handing off an active conversation to handing off an active conversation to another agent. another agent. Think about getting transferred on the Think about getting transferred on the phone to someone else. An agent or a phone to someone else. An agent or a routine is a handoff. So a handoff is an routine is a handoff. So a handoff is an agent or a routine. Well, so this gets agent or a routine. Well, so this gets back to our issue, right? It's often back to our issue, right? It's often difficult to distinguish between tools, single tool agents, and agent teams. We can refer to a single tool agent as We can refer to a single tool agent as simply a tool. simply a tool. And when we talk about handoffs and when we talk about handoffs and routines, routines, routines, we can define this handoff we can define this handoff between two agents between two agents as an agent itself or or as a routine. as an agent itself or or as a routine. Remember the patterns, right? ## [00:43:44 - 00:44:17] Remember the patterns, right? The multi-agent pattern of handoffs as The multi-agent pattern of handoffs as tools is working here tools is working here in OpenAI Agents SDK. Once agents in OpenAI Agents SDK. Once agents express the intent to make a handoff, express the intent to make a handoff, it's time to make it happen. In other it's time to make it happen. In other words, once agents reason, it's time to words, once agents reason, it's time to take action. It's time to call the tool. take action. And so It's time to call the function. And so the Agents SDK the Agents SDK is going to is going to try to at least according to its docs ## [00:44:17 - 00:44:49] try to at least according to its docs give us enough features to be worth give us enough features to be worth using using using and to work great out of the box to keep and to work great out of the box to keep it real simple. The main features we see it real simple. The main features we see a couple of them couple of our good a couple of them couple of our good friends here are agent loop handoffs friends here are agent loop handoffs function tools. function tools. The core primitives The core primitives there's just a few of them there's just a few of them to hopefully make it easy to learn and to hopefully make it easy to learn and adapt adapt adapt are agents ## [00:44:49 - 00:45:20] are agents are agents handoffs and guard rails. agents have handoffs and guard rails. agents have replaced this idea of replaced this idea of routines. You'll see. routines. And so we can kind of notice that these And so we can kind of notice that these these guard rails, we might consider these guard rails, we might consider these also as kind of agents where these also as kind of agents where we're, you know, imagine constraining we're, you know, imagine constraining the ability to give refunds. For the ability to give refunds. For instance, instance, instance, before we call the refund tool, we need before we call the refund tool, we need a guard rail on that. And so altogether, a guard rail on that. And so altogether, these three primitives ## [00:45:20 - 00:45:55] these three primitives produce a way for us to build very produce a way for us to build very complex systems. We're going to build complex systems. We're going to build today for you a research bot. We're today for you a research bot. We're going to have a number of different going to have a number of different pieces of this puzzle, including a pieces of this puzzle, including a planner agent, a search agent, and a planner agent, a search agent, and a writer agent. And as we've discussed before, we need the OpenAI Agents SDK to produce we need the OpenAI Agents SDK to produce more than just a simple response. We more than just a simple response. We need it to actually be able to provide ## [00:45:55 - 00:46:27] need it to actually be able to provide our app with some agency. We need it to our app with some agency. We need it to actually be able to take ChatGBT actually be able to take ChatGBT and to give it some agency when we tell and to give it some agency when we tell it to do agentic search. And as we'll it to do agentic search. And as we'll see today, we're kind of doing uh we're see today, we're kind of doing uh we're kind of doing multi-agent agentic kind of doing multi-agent agentic search. search. We might say that it's it's even heading We might say that it's it's even heading towards something like a deep research. towards something like a deep research. Although it's it's not there yet. We will get there with time in this series. And so today's build, we're going to And so today's build, we're going to leverage routers, tools, planning, and ## [00:46:27 - 00:46:59] leverage routers, tools, planning, and we're going to leverage orchestration we're going to leverage orchestration from a supervision from a supervision agent. To show us how all this works in agent. To show us how all this works in code, we head over to none other than code, we head over to none other than the LLM wizard himself. Whiz, walk us the LLM wizard himself. Whiz, walk us through getting a gentic today. Oh, through getting a gentic today. Oh, we're going to get so agentic, it'll we're going to get so agentic, it'll blow your minds. Okay, so uh easy peasy blow your minds. Okay, so uh easy peasy lemon squeezy. We're going to do some lemon squeezy. We're going to do some agent stuff and uh we're going to have a agent stuff and uh we're going to have a fun time. the big thing here is uh ## [00:46:59 - 00:47:29] fun time. the big thing here is uh that we want to use the agent. First of that we want to use the agent. First of all, I'm going to zoom in so you can see all, I'm going to zoom in so you can see what I'm looking at. Second of all, what I'm looking at. Second of all, we're going to use the Agents SDK uh as we're going to use the Agents SDK uh as well as some of the things we picked well as some of the things we picked up from our our friend uh Responses API. up from our our friend uh Responses API. I'm just going to make sure my screen is I'm just going to make sure my screen is like uh there we go. A little bit a like uh there we go. A little bit a little bit less cringe for you guys. little bit less cringe for you guys. Okay, we love to see it. And the idea is Okay, we love to see it. And the idea is pretty straightforward. We're going to pretty straightforward. We're going to leverage MCP. We're going to leverage uh leverage MCP. We're going to leverage uh web search. Uh we're going to we're ## [00:47:29 - 00:48:02] web search. Uh we're going to we're going to kind of do what we've done going to kind of do what we've done already with the Responses API, but with already with the Responses API, but with a uh the Agents SDK. As you can see, we a uh the Agents SDK. As you can see, we have a bunch of beautifully formatted have a bunch of beautifully formatted markdown brought to you by the our good markdown brought to you by the our good friends at GPT-4o friends at GPT-4o codecs. codecs. So hopefully the formatting of the So hopefully the formatting of the markdown is a little bit less painful. markdown is a little bit less painful. Uh the first thing we're going to do is Uh the first thing we're going to do is we're going to set up our uh Google uh we're going to set up our uh Google uh API access key. Now the reason we're ## [00:48:02 - 00:48:33] API access key. Now the reason we're going to do this is because we're going to do this is because we're actually going to give access to our actually going to give access to our Google calendar to uh you know to this Google calendar to uh you know to this agent. So the reason we're going to do agent. So the reason we're going to do that is mostly just for funsies. Uh but that is mostly just for funsies. Uh but also this is this is an application I also this is this is an application I know someone like me needs. I have a lot know someone like me needs. I have a lot of meetings throughout the day. Uh we of meetings throughout the day. Uh you know and knowing how to prepare Uh you know and knowing how to prepare for them is something that uh you know I for them is something that uh you know I would I would think to use GPT-4o for I would I would think to use GPT-4o for I would think to use J Chad GBD4. Right? I ## [00:48:33 - 00:49:03] would think to use J Chad GBD4. Right? I would I'd be like, "Yo, Doug, I've got a would I'd be like, "Yo, Doug, I've got a meeting come up. What do I need to do meeting come up. What do I need to do prepare for this? What meetings do I prepare for this? What meetings do I have? Uh you know, I'm a forgetful kind have? Uh you know, I'm a forgetful kind of guy. There you go." So we're going to of guy. So we're going to give access to our calendar. Uh the way give access to our calendar. Uh the way we do this is pretty straightforward. We just use the ooth playground. This is going to generate a temporary key uh going to generate a temporary key uh which I've I've already pre-run the which I've I've already pre-run the notebook Manny. So I'm not going to leak notebook Manny. So I'm not going to leak my API key uh on this on this particular my API key uh on this on this particular event. So no no calendar access for you event. Uh but the idea is pretty ## [00:49:03 - 00:49:34] guys. Uh but the idea is pretty straightforward. We take the OOTH straightforward. We take the OOTH playground uh web application and then playground uh web application and then we add calendar events to it. Bob's your we add calendar events to it. Bob's your uncle. Away we go. Okay. Next thing uncle. Next thing we're going to do is set up our OpenAI we're going to do is set up our OpenAI API key and our Google calendar API key and our Google calendar authorization key. Uh easy. We're going authorization key. We're going to do a bunch of uh imports classic wall to do a bunch of uh imports classic wall of imports. And then we're going to of imports. And then we're going to define some uh some DATMSS, right? So define some uh some DATMSS, right? So because uh Agents SDK uses paidantic, because uh Agents SDK uses paidantic, you'll notice we have a bunch of pyantic ## [00:49:34 - 00:50:05] you'll notice we have a bunch of pyantic base models. And because ChatGPT is a base models. And because ChatGPT is a worldclass model, uh we can make these worldclass model, uh we can make these pretty beefy. As you'll see, these are pretty beefy. As you'll see, these are not uh simple, right? There's a lot of not uh simple, right? There's a lot of fields that we want to capture here. And fields that we want to capture here. And uh this is how we're going to do it. Uh each of these is necessary as a kind of each of these is necessary as a kind of state for our agents going forward. state for our agents going forward. Okay. Then we're going to create the Okay. Then we're going to create the calendar agent. The calendar agent is calendar agent. The calendar agent is going to uh be called the calendar going to uh be called the calendar assistant. You can notice we're setting assistant. You can notice we're setting this up with just agent, right? So this ## [00:50:05 - 00:50:38] this up with just agent, right? So this is the OpenAI Agents SDK uh form of an is the OpenAI Agents SDK uh form of an agent. We give it a name. We give these agent. We give these instructions. You are a calendar instructions. You are a calendar assistant that helps users fetch and assistant that helps users fetch and understand their schedule. When asked understand their schedule. When asked about events for a specific day, about events for a specific day, retrieve all calendar events for that retrieve all calendar events for that day and provide a clear structured day and provide a clear structured summary of the schedule. Include event summary of the schedule. Include event titles, times, locations, and attendees. titles, times, locations, and attendees. And then the only tool this bad boy has And then the only tool this bad boy has is a hosted MCP tool. Now, a hosted MCP is a hosted MCP tool. Now, a hosted MCP tool uh means it's a MCP tool that is tool uh means it's a MCP tool that is hosted somewhere. So, actually the uh hosted somewhere. So, actually the uh the Google calendar MCP is hosted. We ## [00:50:38 - 00:51:10] the Google calendar MCP is hosted. We don't have to run this thing in our don't have to run this thing in our browser, right? Or in our environment. browser, right? This is hosted. All we need to do is This is hosted. All we need to do is pass through our uh SDK. So the tool is pass through our uh SDK. So the tool is a MCP server. What you know we got MCP a MCP server. What you know we got MCP in this bad boy, right? So uh this is in this bad boy, right? So uh this is the idea and this is part of the idea and this is part of the connectors, right? So through the connectors, right? So through the Responses API last time we looked at the Responses API last time we looked at the connectors and the connectors were uh connectors and the connectors were uh you know the way that a user can use o ## [00:51:10 - 00:51:41] you know the way that a user can use o ooth to log in right and then start uh ooth to log in right and then start uh doing cool stuff and you'll notice this doing cool stuff and you'll notice this pattern right is very familiar. So you pattern right is very familiar. So you can imagine in a UI setting we could can imagine in a UI setting we could have the user click a OOTH button have the user click a OOTH button generate their uh their key and then generate their uh their key and then pass this through during the pass this through during the construction of our agent. So this is construction of our agent. So this is the kind of idea that we're going to the kind of idea that we're going to leverage in the future when we move this leverage in the future when we move this to the end to end uh effort. And of to the end to end uh effort. And of course we have our ChatGPT model uh because course we have our ChatGPT model uh because we're using GPD5 these days. There you ## [00:51:41 - 00:52:11] we're using GPD5 these days. There you go. Brand new models. It's real good. Uh go. Uh then we have an event analyzer. This is just a kind of normal uh agent. Normal meaning it doesn't have a tool. So there's no tool here. This is like uh So there's no tool here. This is like uh you know just meant to do something. you know just meant to do something. You could call it a prompt, but it's more could call it a prompt, but it's more than a prompt, right? It's going to have than a prompt, right? It's going to have the ability to work at this problem in the ability to work at this problem in an agent fashion. It's not just like a an agent fashion. It's not just like a oneshot prompt like the Responses API. oneshot prompt like the Responses API. You'll also notice that for ChatGPT, we're You'll also notice that for ChatGPT, we're going to pass in our reasoning effort. going to pass in our reasoning effort. We're going to set our reasoning effort ## [00:52:11 - 00:52:42] We're going to set our reasoning effort to medium for our calendar. uh tool or to medium for our calendar. uh tool or agent, we did not require uh reasoning agent, we did not require uh reasoning efforts. So um this is the idea. We can efforts. We can toggle specific reasoning efforts just toggle specific reasoning efforts just like we did in the Responses API, right? like we did in the Responses API, right? You can kind of see how this is tying You can kind of see how this is tying back into the Responses API. Uh and then back into the Responses API. Uh and then our output type is going to be that our output type is going to be that structured uh base pantic base model structured uh base pantic base model that we created above. Finally, we can that we created above. Finally, we can make a research uh uh agent. The make a research uh uh agent. The research agent is just going to gather ## [00:52:42 - 00:53:16] research agent is just going to gather relevant information. It's going to use relevant information. It's going to use the web search tool. We're going to use a fast slick LM for this. And we're a fast slick LM for this. And we're going to require it to use the tool. Uh this use the tool choice required means this use the tool choice required means it must use the web search tool. You may it must use the web search tool. You may say, well, this is the research agent. Shouldn't we have big thanky? Well, actually all this is doing is it's actually all this is doing is it's searching, right? So that search phase searching, right? So that search phase can be fast and uh and efficient, right? can be fast and uh and efficient, right? And then the synthesization which I And then the synthesization which I don't think is a word but the uh the don't think is a word but the uh the the uh the the eventual ## [00:53:16 - 00:53:46] the uh the the eventual whatever synthesization of the responses whatever synthesization of the responses will be the uh will be the thing that will be the uh will be the thing that requires thinking right so we're just requires thinking right so we're just we're just spamming out web searches for we're just spamming out web searches for this and you'll notice right what we this and you'll notice right what we this is part of the research so we're this is part of the research so we're not just hitting our MCP event we're not just hitting our MCP event we're also searching ing the web to find some also searching ing the web to find some some uh some ways to prepare. And then some uh some ways to prepare. And then finally, we have our preparation guide finally, we have our preparation guide agent which is going to tell us how to agent which is going to tell us how to prepare for these meetings. It's going ## [00:53:46 - 00:54:18] prepare for these meetings. It's going to use all the information gathered so to use all the information gathered so far. And so this one is our big thank far. We're using reasoning effort you agent. We're using reasoning effort high uh using among the best reasoning high uh using among the best reasoning models in the world on its highest most models in the world on its highest most uh you know uh mo most uh intense uh you know uh mo most uh intense setting. Uh but the idea is that we want setting. Uh but the idea is that we want we want to have this uh information we want to have this uh information synthesis be something that's done with synthesis be something that's done with great care. Finally, we build an great care. Finally, we build an orchestrator. The orchestrator just orchestrator. The orchestrator just looks an awful lot like running these looks an awful lot like running these agents than passing the results uh ## [00:54:18 - 00:54:50] agents than passing the results uh between each other. I'm going to go between each other. I'm going to go ahead and scroll through this just ahead and scroll through this just because we've seen this many times because we've seen this many times before. Uh and then finally uh show you before. Uh and then finally uh show you an example of it running. So I ran this an example of it running. So I ran this with a event that I that I was uh that I with a event that I that I was uh that I was working on today. perhaps no one's was working on today. perhaps no one's surprise which is the OpenAI Agents SDK surprise which is the OpenAI Agents SDK and it gave me a lot of different ways and it gave me a lot of different ways to prepare as well as it gave me a bunch to prepare as well as it gave me a bunch of uh different questions and suggested of uh different questions and suggested talking points uh you know that you talking points uh you know that you might you might have uh heard come up a ## [00:54:50 - 00:55:22] might you might have uh heard come up a little bit in this event uh and that's little bit in this event uh and that's it right so the Agents SDK it's just it right so the Agents SDK it's just another agents framework yes okay true another agents framework yes okay true but uh it works really well with that but uh it works really well with that same responses is uh you know API that same responses is uh you know API that we've seen before. You can see you can we've seen before. You can see you can do a bunch of extensions to it. But the do a bunch of extensions to it. But the big idea is that we can build off of big idea is that we can build off of this base, right? More connectors, this base, right? More connectors, caching, some personalization, allowing caching, some personalization, allowing people to change the system prompts, people to change the system prompts, creating a UI, uh you know, doing more ## [00:55:22 - 00:55:52] creating a UI, uh you know, doing more fancy things with the uh you know, the fancy things with the uh you know, the actual calendar events like scheduling. actual calendar events like scheduling. Uh all of this are the key pieces of Uh all of this are the key pieces of ChatGPT that we're going to eventually ChatGPT that we're going to eventually be building as we move through the rest be building as we move through the rest of the series. Uh but for today uh we of the series. Uh but for today uh we just built a very simple agent and uh just built a very simple agent and uh you know very simple agent in 2025 late you know very simple agent in 2025 late 2025 looks a lot different than a very 2025 looks a lot different than a very simple agent in 2023. Uh with the simple agent in 2023. Uh with the inclusion of MCP and reasoning mode uh ## [00:55:52 - 00:56:22] inclusion of MCP and reasoning mode uh you know as as standards we're able to you know as as standards we're able to do a lot cooler things. So, that's this do a lot cooler things. So, that's this part of the uh the presentation. I'm part of the uh the presentation. I'm going to pass you guys back to Greg, but going to pass you guys back to Greg, but before I do, I'm going to ask you to before I do, I'm going to ask you to subscribe and ring the bell subscribe and ring the bell notification. Uh we're here every notification. Uh we're here every Wednesday. Rain, shine, sleep, snow. Uh Wednesday. Uh we love doing these events, guys. And uh we'll we'll see you we'll see you in the we'll we'll see you we'll see you in the next one. Uh back to Dr. Greg. next one. All right. Thanks, Whiz. So, what we'll All right. So, what we'll go ahead and do is we'll just do a quick go ahead and do is we'll just do a quick wrap here and then we'll we'll do some ## [00:56:22 - 00:56:54] wrap here and then we'll we'll do some some Q&amp;A. I see a couple questions in some Q&amp;A. I see a couple questions in the chat. So, we covered a lot of ground the chat. So, we covered a lot of ground today everybody. So, you know, in today everybody. So, you know, in conclusion, we've got a lot of things we conclusion, we've got a lot of things we could conclude, but we saw that agents could conclude, but we saw that agents or patterns. We want to define an agent or patterns. We want to define an agent as a system that can leverage reasoning as a system that can leverage reasoning to make dynamic decisions in an to make dynamic decisions in an application flow. Multi- aent systems application flow. Multi- aent systems are ones that can leverage reasoning are ones that can leverage reasoning from multiple independent agents. And we from multiple independent agents. And we want to really be sure we need it before want to really be sure we need it before we build it. We need the Agents SDK on ## [00:56:54 - 00:57:26] we build it. We need the Agents SDK on top of the Responses API to do more than top of the Responses API to do more than get a response from an API to do get a response from an API to do something a little bit more agentic. something a little bit more agentic. So Whiz, I see a couple questions in the So Whiz, I see a couple questions in the chat here. Um, let's see. Uh, chat here. Uh, so first one is from Arab Goch. For a complex task that a multi- aent system complex task that a multi- aent system is attempting to service, how do you is attempting to service, how do you determine that the task is satisfactory determine that the task is satisfactory complete? complete? Hashevals ## [00:57:26 - 00:57:57] Hashevals Hashevals answer. answer. That's like a billion-dollar question. I mean, uh, you rely on the entity mean, uh, you rely on the entity that started the job to tell you if the that started the job to tell you if the job is complete or not. Be that human, job is complete or not. Be that human, be that agent. Uh, be that agent. Uh, that's it. I mean, that's it. I mean, classic. You know, it it it's one of classic. You know, it it it's one of those things where for some tasks this those things where for some tasks this is easy. Did you fill all the form is easy. Did you fill all the form fields out? Did you uh do tasks one, fields out? Did you uh do tasks one, two, three, four, and five? Right? But two, three, four, and five? But for some uh tasks, this is for some uh tasks, this is extraordinarily difficult. Like did you ## [00:57:57 - 00:58:28] extraordinarily difficult. Like did you come up with a business idea worth $1 come up with a business idea worth $1 million and an actual plan to create it? million and an actual plan to create it? Right? Like did you can't really like Right? Like did you can't really like when is that complete? And when when is that complete? Right? And when is that satisfactory complete? So, uh, it's going to come down to a lot down to it's going to come down to a lot down to the entity that created the job to to the entity that created the job to to make that determination. make that determination. Okay, quick question from cake seven Okay, quick question from cake seven eater. Let's say you have an eater. Let's say you have an orchestrator supervisor. Where is the orchestrator supervisor. Where is the reasoning being done? Is it by the reasoning being done? Is it by the orchestrator orchestrator which then dispatches the orders to the ## [00:58:28 - 00:59:00] which then dispatches the orders to the sub aents or is it done somewhere else? sub aents or is it done somewhere else? Yeah, this is a really good question Yeah, this is a really good question actually. So actually. So for most for the most part we don't want for most for the most part we don't want it to be done by the orchestrator the it to be done by the orchestrator the reasoning we want the orchestrator to reasoning we want the orchestrator to just kind of like move between jobs just kind of like move between jobs right like move between different agents right like move between different agents uh and then pass off to a agent that's uh and then pass off to a agent that's good at you know this whatever requires good at you know this whatever requires reasoning so in the kind of hierarchical reasoning so in the kind of hierarchical agent structure we don't want our ## [00:59:00 - 00:59:31] agent structure we don't want our orchestrator to be a heavy reasoner we orchestrator to be a heavy reasoner we just want it to route uh requests just want it to route uh requests correctly. Uh though you can you can correctly. Uh though you can you can think of uh of course you can think of think of uh of course you can think of examples where this is this is different examples where this is this is different and uh you know you want that and uh you know you want that some small piece of your orchestration some small piece of your orchestration pipeline to be uh to be able to to think pipeline to be uh to be able to to think through problems uh well but I would say through problems uh well but I would say it's like a general rule not necessary. it's like a general rule not necessary. So the planner you want to separate So the planner you want to separate planning from literal yes planning from literal yes orchestration and routing. ## [00:59:31 - 01:00:02] orchestration and routing. That's right. Yeah. like a planning a That's right. like a planning a plan creation agent versus a plan creation agent versus a orchestrator that does planning. Yeah, orchestrator that does planning. Yeah, that's right. One of them is the that's right. One of them is the strategist and one of them is the strategist and one of them is the tactician. tactician. That's right. Getting stuff done. Okay. Pointing. Boom. You go here. You Pointing. go here. That's right. You agent. Go. Yeah. That's agent. That's right. right. All right. So, uh Charles, I think I All right. So, uh Charles, I think I think what Charles is asking here is think what Charles is asking here is people don't want to use OpenAI agents people don't want to use OpenAI Agents SDK. Is there another agent software ## [01:00:02 - 01:00:34] SDK. Is there another agent software development kit? Like they stole the development kit? Like they stole the name of this. Like is there another is name of this. Like is there another is there another orchestration framework there another orchestration framework that we would recommend? that we would recommend? I believe we have a playlist on YouTube I believe we have a playlist on YouTube of all of the ones that we've talked of all of the ones that we've talked about. Uh we're going to continue in 20 about. We're going to continue to late 2025. We're going to continue to advocate for Lang graph uh in the Lang advocate for Lang graph uh in the Lang chain ecosystem. uh it is still chain ecosystem. uh it is still a great way to get started with agents, a great way to get started with agents, but we've done events on on a some ## [01:00:34 - 01:01:06] but we've done events on on a some handful or a dozen of different handful or a dozen of different frameworks that are open source and frameworks that are open source and aren't uh now now if what you mean is aren't uh now now if what you mean is like I don't like OpenAI models because like I don't like OpenAI models because the OpenAI Agents SDK is open source like the OpenAI Agents SDK is open source like it's fully available for you to use and it's fully available for you to use and it doesn't just work with OpenAI models, it doesn't just work with OpenAI models, right? So if you just mean I don't like right? So if you just mean I don't like the uh I don't like the OpenAI models the uh I don't like the OpenAI models then you would just point at a different then you would just point at a different model uh which you can do with the open ## [01:01:06 - 01:01:37] model uh which you can do with the open source uh OpenAI Agents SDK. Yeah. source uh OpenAI Agents SDK. All right. Dope. Thanks Wiz. Thanks for All right. Thanks for it's fun getting a Gentic today. Um, it's fun getting a Gentic today. Um, next time uh we're talking about next time uh we're talking about endtoend endtoend endtoend vibes. We got some vividity vibes going. vibes. You're not going to vibe code live, but You're not going to vibe code live, but we are going to get the actual we are going to get the actual ChatGPT ChatGPT ChatGPT frontend looking thing spun up next week ## [01:01:37 - 01:02:09] frontend looking thing spun up next week and uh and deployed. So, it should be a and uh and deployed. So, it should be a lot of fun. I'm pumped for it. We'll see lot of fun. We'll see you back then. you back then. All right, guys. Thanks for joining us All right, guys. Thanks for joining us for another weekly Wednesday YouTube for another weekly Wednesday YouTube live event at AI Makerspace. We are on a live event at AI Makerspace. We are on a mission to create the world's leading mission to create the world's leading community for people like you who want community for people like you who want to build, ship, and share production LLM to build, ship, and share production LLM applications. If you haven't yet joined applications. If you haven't yet joined our Discord community is full of a bunch our Discord community is full of a bunch of amazing, really competent, and very of amazing, really competent, and very cool people, many of whom you'll see in ## [01:02:09 - 01:02:41] cool people, many of whom you'll see in the chat today, crushing it. Shout out the chat today, crushing it. Shout out to all you guys joining us live. And if you're looking to accelerate your And if you're looking to accelerate your LM application development, we can help LM application development, we can help you out. We have solutions for you out. We have solutions for individuals like our flagship AI individuals like our flagship AI engineering boot camp and for teams. So engineering boot camp and for teams. So you can help do the most in 2025 and you can help do the most in 2025 and 2026 with the team you already have, not 2026 with the team you already have, not the team you wish you could hire. Uh the team you wish you could hire. Uh with that, we're going to go ahead and with that, we're going to go ahead and call it for the day. It's been a call it for the day. It's been a pleasure. Part three, how to build chat ## [01:02:41 - 01:03:12] pleasure. Part three, how to build ChatGPT. We'll be back for for part four ChatGPT. We'll be back for for part four next week. Actually putting this app next week. Actually putting this app together with prompting with RAG with together with prompting with RAG with agents fully context engineered ready to agents fully context engineered ready to get the in and get the out and we'll get the in and get the out and we'll keep going from there. Thanks for keep going from there. Thanks for joining us again. Until next time, keep joining us again. Until next time, keep building, shipping, and sharing. We'll building, shipping, and sharing. We'll do the same. See you next Wednesday, do the same. See you next Wednesday, guys. guys. But Greg, how do they get started? Building, shipping, and sharing. Getting started is the hardest part. like it was ## [01:03:12 - 01:03:44] started is the hardest part. like it was for you and for me. You can get started for you and for me. You can get started with the AI engineer challenge and you with the AI engineer challenge and you can share it in the build ship share can share it in the build ship share channel on Discord. Links in the channel on Discord. Links in the description. What if they want to description. What if they want to accelerate their ability? Well, we accelerate their ability? Well, we actually have a 10-week intensive boot actually have a 10-week intensive boot camp where you learn to build, ship, and camp where you learn to build, ship, and share production ready LLM applications share production ready LLM applications every single week. The AI engineering every single week. The AI engineering boot camp cohort starting soon. We'll boot camp cohort starting soon. We'll have you building, shipping, and sharing have you building, shipping, and sharing like a legend in no time. We'll see you ## [01:03:44 - 01:03:48] like a legend in no time. We'll see you in class.