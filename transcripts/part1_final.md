# Part 1: Prompting & Responses API ## [00:00:02 - 00:00:34] Hey Whiz, today we're going to start building our very own ChatGPT. Are you building our very own ChatGPT. Are you excited for this series, dude? I couldn't be more excited. It you know, we're trying to know, we're trying to recreate the experience of ChatGPT with recreate the experience of ChatGPT with OpenAI's technology. Isn't that what a OpenAI's technology. Isn't that what a future we live in? future we live in? The best. Yeah, we're coming The best. Yeah, we're coming up on three years. uh the chat up on three years. uh the chat anniversary, let's say November 2022. anniversary, let's say November 2022. And I think a lot of people, especially ## [00:00:34 - 00:01:06] And I think a lot of people, especially today, and rightly so, underestimate all today, and rightly so, underestimate all that goes in to ChatGPT. So today, that goes in to ChatGPT. So today, we're going to break down sort of what we're going to break down sort of what the key features and components are, and the key features and components are, and we'll give people some insight into we'll give people some insight into all of the backend stuff that's really all of the backend stuff that's really going on. It's still the same old chat going on. It's still the same old chat interface, but that's just the interface interface, but that's just the interface behind the scenes. That's where most of behind the scenes. That's where most of the magic happens. Isn't that right? the magic happens. Yeah. I mean, it's again, we're going to ## [00:01:06 - 00:01:41] Yeah. I mean, it's again, we're going to use the models. We're going to use their use the models. We're going to use their APIs. We're going to go over all of APIs. We're going to go over all of this, but we're going to effectively this, but we're going to effectively use those tools to recreate the use those tools to recreate the experience to show people how it's experience to show people how it's happening behind the scenes or at least, happening behind the scenes or at least, you know, as far as we can tell given you know, as far as we can tell given the technology uh that we have access to the technology uh that we have access to just in order to see how complex these just in order to see how complex these stacks really are and how, you know, the stacks really are and how, you know, the words like we used to say kind of in a words like we used to say kind of in a like a memey or p, you know, a in in like a memey or p, you know, a dismissive way like uh you know, hey, ## [00:01:41 - 00:02:13] dismissive way like uh you know, hey, it's just what ChatGPT can do. But it's just what ChatGPT can do. But these days, ChatGPT is doing a whole these days, ChatGPT is doing a whole lot. lot. It's doing a whole lot. And it really is It's doing a whole lot. And it really is a very very multi- multi- aent system a very very multi- multi- aent system behind this behind the scenes here. Like behind this behind the scenes here. Like in so far as we have access to build in so far as we have access to build stuff as developers through APIs, we're stuff as developers through APIs, we're going to build everything we can from going to build everything we can from the ground up. It starts in this the ground up. It starts in this session. This is the kickoff part one. ## [00:02:13 - 00:02:44] session. This is the kickoff part one. Today we cover like the core program Today we cover like the core program from whence all else will come. And it's from whence all else will come. And it's actually quite simple. You're contained actually quite simple. You're contained in a notebook today. Isn't that right? in a notebook today. This is a this is an introduction to the This is a this is an introduction to the tool we will use to build something uh tool we will use to build something uh with with greater complexity. So that's with with greater complexity. So that's right. For right now, we're still locked right. For right now, we're still locked in the notebook. We're still It's easy in the notebook. We're still It's easy breezy. That's right. But we have to breezy. But we have to ease in. We got to dip our feet in ease in. We got to dip our feet in before we really start uh ## [00:02:44 - 00:03:15] before we really start uh quickly accelerating beyond quickly accelerating beyond just a notebook. Yeah. just a notebook. So, it's kind of like we went to the So, it's kind of like we went to the store, we bought a plant in a planter, store, we bought a plant in a planter, and we're going to we're going to sort and we're going to we're going to sort of bring that back and start growing a of bring that back and start growing a garden here soon enough. Okay. All garden here soon enough. All right. Beautiful, Whiz. Well, uh I'm right. Well, uh I'm excited for the discussions today. Even excited for the discussions today. Even though it's an introductory topic, though it's an introductory topic, there's a lot of really fun, there's a lot of really fun, interesting, agentic things happening in interesting, agentic things happening in the industry that we get to highlight. the industry that we get to highlight. Revisiting classic core concepts and ## [00:03:15 - 00:03:46] Revisiting classic core concepts and code. One of our favorite things to do. code. Let's go ahead and kick this thing off. We'll see you back in a bit. Uh, all right. And with that, we are Uh, all right. And with that, we are pumped to kick off part one prompting. pumped to kick off part one prompting. Should we even call it that anymore? and the Responses API. This is going to the Responses API. This is going to allow us to have the glue that we need allow us to have the glue that we need to connect our very own ChatGPT to connect our very own ChatGPT application together. This is the first application together. This is the first of many sessions to come on how to build ## [00:03:46 - 00:04:17] of many sessions to come on how to build your very own ChatGPT in 2025. So, your very own ChatGPT in 2025. So, thanks for joining us today. If you're a thanks for joining us today. If you're a beginner, welcome. If you're a super advanced user, we hope you enjoy digging advanced user, we hope you enjoy digging into the core concepts and code at the into the core concepts and code at the edge in 2025 as much as we do. If you edge in 2025 as much as we do. If you want to jump in on any discussion or want to jump in on any discussion or conversation topic, please do it conversation topic, please do it directly in the YouTube live chat or in directly in the YouTube live chat or in a comment on your viewing platform. And a comment on your viewing platform. And with that, let's kick this thing off with that, let's kick this thing off everybody. How to build ChatGPT part ## [00:04:17 - 00:04:48] everybody. How to build ChatGPT part one prompting and the Responses API. So one prompting and the Responses API. So because this is the very first of our because this is the very first of our sessions on how to build ChatGPT, we sessions on how to build ChatGPT, we want to want to really outline the want to want to really outline the breadth and scope of this series for you breadth and scope of this series for you first and that'll allow us to get first and that'll allow us to get started building the core of what will started building the core of what will become our backend. We want to become our backend. We want to understand the Responses API and its understand the Responses API and its lineage starting with the chat lineage starting with the Chat Completions API. We want to understand ## [00:04:48 - 00:05:20] completions API. We want to understand how to let's say prompt engineer how to let's say prompt engineer our application our application in the age of agents and uh of course in the age of agents and uh of course whizzle come in and give us the demo we whizzle come in and give us the demo we need to really get started. So first a need to really get started. So first a quick overview of really the product quick overview of really the product ChatGPT more than this series. ChatGPT more than this series. We'll then talk about the OpenAI API We'll then talk about the OpenAI API known world round by AI engineers ## [00:05:20 - 00:05:50] known world round by AI engineers building, shipping, and sharing their building, shipping, and sharing their own unique applications. And then we own unique applications. And then we want to really dig into not just want to really dig into not just prompting best practices that everybody prompting best practices that everybody knows already, but more specifically we knows already, but more specifically we want to take a look at some of the want to take a look at some of the developer prompting best practices that developer prompting best practices that we'll need to build we'll need to build a truly agentic ChatGPT today a truly agentic ChatGPT today using some of the latest models that we using some of the latest models that we have access to. Okay. So first let's ## [00:05:50 - 00:06:22] have access to. Okay. So first let's take a look at ChatGPT. Um, this is the take a look at ChatGPT. Um, this is the classic interface. This is from our our classic interface. This is from our our business account here at AI Makerspace. business account here at AI Makerspace. What's on your mind today? The classic What's on your mind today? The classic chat. Well, if you click this little chat. Well, if you click this little plus button right here, you'll see that plus button right here, you'll see that you get access to a bunch of different you get access to a bunch of different stuff. And if we could kind of take a stuff. And if we could kind of take a closer look at this, maybe zoom in a closer look at this, maybe zoom in a bit, we can start to see that like bit, we can start to see that like there's actually a lot going on. there's actually a lot going on. For instance, if I want to just add some ## [00:06:22 - 00:06:38] For instance, if I want to just add some files, little file search action. Boom. files, little file search action. We might call that some retrieval We might call that some retrieval augmentation of our prompt or our augmentation of our prompt or our context that we're putting in before I context that we're putting in before I send it send it ## [00:07:43 - 00:08:15] to our context before we send it to the model. But of course, that's not the to the model. But that's not the only place we see RAG But that's not the only place we see RAG here. In fact, all of these connectors here. And uh of course some of are also RAG. And uh of course some of them are a little bit more them are a little bit more business-oriented on this business business-oriented on this business account. Some of them make things a account. Some of them make things a little bit easier than uh just basically little bit easier than uh just basically doing plain old RAG. Uh but they're all doing plain old RAG. Uh but they're all under the umbrella of RAG. This will be under the umbrella of RAG. This will be sort of a focus of our second session. sort of a focus of our second session. How do we build these sorts of features? And then we might talk a little bit And then we might talk a little bit about agents. Now, one of the things about agents. Now, one of the things that we don't even see on here is that that we don't even see on here is that there is an agentic search capability there is an agentic search capability built in. We don't have to sort of tell built in. We don't have to sort of tell ChatGPT to use the internet. We used to ChatGPT to use the internet. We used to at one point in time, but now it's baked at one point in time, but now it's baked in that we can do internet searches, we in that we can do internet searches, we can retrieve information, uh we can get can retrieve information, uh we can get current information, and we can add that current information, and we can add that to our context before we send it to the model. But of course, that's not the only place agents come into play. Uh only place agents come into play. Uh agent mode, of course, is glaring here. And what does that even mean? Well, that And what does that even mean? Well, that actually means a lot, as we'll see. It's not just not just not just agentic reasoning. It's like true agentic reasoning. It's like true multimodal computer use and multimodal computer use and a lot of other really nuanced agentic a lot of other really nuanced agentic things going on to put that together. It things going on to put that together. It sort of stacks up with a few releases ## [00:08:15 - 00:08:48] sort of stacks up with a few releases that OpenAI has come out with in recent that OpenAI has come out with in recent months and years. And of course, there's months and years. And of course, there's deep research, which is maybe the most deep research, which is maybe the most successful multi-agent application of successful multi-agent application of 2025, 2025, 2025, certainly to date across all big model certainly to date across all big model providers and has become a bit of a providers and has become a bit of a mainstay in any application that we mainstay in any application that we might pick up off the shelf and use any might pick up off the shelf and use any competitors to ChatGPT. But it goes on, competitors to ChatGPT. But it goes on, right? But we have pictures. Uh we have ## [00:08:48 - 00:09:19] right? But we have pictures. Uh we have the canvas the canvas the canvas sort of more interactive user interface sort of more interactive user interface that maybe as developers we don't use as that maybe as developers we don't use as much but that is quite interesting to much but that is quite interesting to check out to learn about and to actually check out to learn about and to actually see just how old this feature is. Of see just how old this feature is. Of course, study and learn was just course, study and learn was just released heading into this school year. released heading into this school year. study mode as you know universities study mode as you know universities around the world have to deal with the around the world have to deal with the fact that kids are going to keep using fact that kids are going to keep using ChatGPT and so are university ## [00:09:19 - 00:09:52] ChatGPT and so are university professors professors professors and this is just within the little plus and this is just within the little plus right so I mean this is just all the right so I mean this is just all the stuff that's hidden within the actual stuff that's hidden within the actual chat bar and it's not even all the stuff chat bar and it's not even all the stuff we can zoom back out we can think uh we can zoom back out we can think uh about the selection up top that we might about the selection up top that we might be familiar with how we can select be familiar with how we can select different models. Maybe we can zoom in a different models. Maybe we can zoom in a little bit here uh and take a closer little bit here uh and take a closer look. look. If we want to be able to select models, ## [00:09:52 - 00:10:23] If we want to be able to select models, how do we do that exactly? how do we do that exactly? And how do we have the model decide And how do we have the model decide on selecting reasoning versus on selecting reasoning versus non-reasoning? non-reasoning? How is that connected to the types of How is that connected to the types of agents we might be leveraging elsewhere agents we might be leveraging elsewhere within this chat interface? within this chat interface? How might we think about leveraging How might we think about leveraging different LLMs different LLMs or, you know, ## [00:10:23 - 00:10:55] or, you know, even just engaging directly with voice? even just engaging directly with voice? You know, this was released last week You know, this was released last week and as part of our mastermind session we and as part of our mastermind session we do internally at AMaker Space, uh we do internally at AMaker Space, uh we talked about the real time API voice talked about the real time API voice updates and Whiz demoed them for updates and Whiz demoed them for everybody. There's just so much going everybody. I mean, even zooming back out, you on. I mean, even zooming back out, you can kind of look up in the corner here can kind of look up in the corner here and you can see that you can kind of do and you can see that you can kind of do that incognito chat. You can kind of that incognito chat. You can kind of turn off the temporary chat here. ## [00:10:55 - 00:11:27] turn off the temporary chat here. There's so many things and whiz I just There's so many things and whiz I just want to have a quick discussion about want to have a quick discussion about this. We had initially outlined the this. We had initially outlined the series as like a sevenparter but as I series as like a sevenparter but as I was preparing today's session as we were was preparing today's session as we were talking more about this you know there's talking more about this you know there's there's images and canvas and study mode there's images and canvas and study mode and real time voice and memory and and real time voice and memory and what about the stuff that's going to be what about the stuff that's going to be released next week we don't even know released next week we don't even know about. Um about. Um there's going to be a lot of sessions. How many of these are really necessary ## [00:11:27 - 00:11:59] How many of these are really necessary for most people building most things? for most people building most things? Um, are they going to have some subset, Um, are they going to have some subset, some very small subset of these some very small subset of these features? Is this more just for the big features? Is this more just for the big model providers that you would want to model providers that you would want to do this or are we starting to see do this or are we starting to see production applications that look more production applications that look more and more like ChatGPT every day? and more like ChatGPT every day? Yeah, I mean it's a it's a it's a great Yeah, I mean it's a it's a it's a great question because you know the answer is question because you know the answer is subset for sure. like you don't need to subset for sure. like you don't need to build all of ChatGPT like not build all of ChatGPT like not everything is trying to be the everything is trying to be the everything app right and I think that's ## [00:11:59 - 00:12:30] everything app right and I think that's important to keep in mind but what's important to keep in mind but what's also important to keep in mind is that also important to keep in mind is that we have uh the ability to build all of we have uh the ability to build all of this right and so I think you know kind this right and so I think you know kind of walking through what is possible just of walking through what is possible just with a very limited on rails set of with a very limited on rails set of tools right uh is is tools right uh is is it's exponentially more than what was it's exponentially more than what was possible when we did our first chat possible when we did our first chat anniversary, right? And we were like anniversary, right? And we were like super excited that you could just talk super excited that you could just talk to the model and it wouldn't always lie. ## [00:12:30 - 00:13:02] to the model and it wouldn't always lie. Uh I think this is the Uh I think this is the kind of progression, right? Yes, the kind of progression, right? Yes, you'll only take a subset of these you'll only take a subset of these things, but you can do all of it. Uh and things, but you can do all of it. Uh and that's something that and as you can that's something that and as you can see, you can do as you will see over the see, you can do as you will see over the course of our many sessions. uh you course of our many sessions. uh you can do all of it relatively low lift for can do all of it relatively low lift for each individual component. Tying it all each individual component. Tying it all together is is integration hell exists together is is integration hell exists and it's real, right? But uh but you can and it's real, right? But uh but you can do each of these things and it's like do each of these things and it's like it's a single one-hour session and you ## [00:13:02 - 00:13:33] it's a single one-hour session and you can get her done. can get her done. That's right. I mean That's right. I mean realistically, you know, we're seeing a realistically, you know, we're seeing a lot about the workforce and layoffs lot about the workforce and layoffs every day. What was it? Salesforce every day. Salesforce today. It's like we can do more with today. It's like we can do more with like like like it's almost maybe the best thing you it's almost maybe the best thing you could even put on your resume today if could even put on your resume today if you want to be a developer. It's like I you want to be a developer. It's like I built my own Chad GPT. Check it out. built my own Chad GPT. This is part of the reason that we want This is part of the reason that we want to do this and sort of give this as to do this and sort of give this as a resource to the community because a resource to the community because being able to do this and then requiring ## [00:13:33 - 00:14:04] being able to do this and then requiring it to be done as a product are two it to be done as a product are two different things that that are serving different things that that are serving different goals and I think it's different goals and I think it's important to sort of distinguish for important to sort of distinguish for engineers to be able to do this. I mean engineers to be able to do this. I mean this is what makes you the big dollary this is what makes you the big dollary dues today, right? I mean this is this dues today, right? I mean this is this is the stuff. is the stuff. Well, it's like if you could do this Well, it's like if you could do this whole subset of things, right? If you whole subset of things, right? If you can do every individual core component, can do every individual core component, the kind of implication there is the kind of implication there is that there's not many things you're that there's not many things you're going to not be able to rise to the going to not be able to rise to the challenge of, right? And so, uh, when challenge of, right? And so, uh, when companies are looking for people, ## [00:14:04 - 00:14:34] companies are looking for people, especially in the AI space, we hear over especially in the AI space, we hear over and over again with the MIT study and over again with the MIT study and with the this and that study and with with the this and that study and with people talking about how to stay people talking about how to stay relevant in the age of AI, like relevant in the age of AI, like flexibility and adaptability are one of flexibility and adaptability are one of the key things that uh that people need the key things that uh that people need and people are looking for. And you and people are looking for. And you know, being able to do all of this, uh, know, being able to do all of this, uh, it it helps put the proof in the it it helps put the proof in the pudding, right? That you are adaptable, pudding, right? That you are adaptable, that you can, uh, you know, you create that you can, uh, you know, you create what needs to be created, not just ## [00:14:34 - 00:15:06] what needs to be created, not just that you can build, chip, and share like that you can build, chip, and share like a legend. a legend. Yeah. And get paid to do it. Hopefully create tons of value for your Hopefully create tons of value for your company, tons of value for you as well company, tons of value for you as well along the way. Yes. along the way. Okay. So I mean this isn't as we're Okay. So I mean this isn't as we're going to break it down this this isn't going to break it down this this isn't super super super complex complex complex although each individual thing if we go although each individual thing if we go deep enough into the models if we go deep enough into the models if we go deep into into the technology it's going deep into into the technology it's going to but we're building here and this is to but we're building here and this is to this is sort of meant to mimic ## [00:15:06 - 00:15:38] to this is sort of meant to mimic building of real applications when they building of real applications when they need these types of features as more and need these types of features as more and more applications will need uh in the more applications will need uh in the many months and years to come. many months and years to come. Okay, Okay, Okay, that's the one. that's the one. All right. Well, uh, then let's go ahead All right. Well, uh, then let's go ahead and introduce our very first topic whiz and introduce our very first topic whiz and we'll see back in just a bit for and we'll see back in just a bit for discussion. So, where does the story discussion. So, where does the story begin? The story begins, guys, with the begin? The story begins, guys, with the OpenAI API or OpenAI API or formally we might call this the OpenAI formally we might call this the OpenAI chat completions ## [00:15:39 - 00:16:11] API. Now, for those of you that have been in Now, for those of you that have been in the game for a while, you might have the game for a while, you might have been familiar with the March 2023 been familiar with the March 2023 terminology, the system user assistant terminology, the system user assistant role terminology. For those of you role terminology. For those of you getting in the game just now in 2025, getting in the game just now in 2025, you can go ahead and forget about that you can go ahead and forget about that system role because as of 2025, system role because as of 2025, we're talking about the developer role. we're talking about the developer role. This is the age of development of so This is the age of development of so many of these AI applications and this ## [00:16:11 - 00:16:44] many of these AI applications and this is where you as the developer are going is where you as the developer are going to be doing a lot of work to set the to be doing a lot of work to set the context and set the vibe and set context and set the vibe and set really the behavior really the behavior of your applications. So here's the big of your applications. So here's the big idea with the Chat Completions API. We idea with the Chat Completions API. We want to pass a list of messages, a list want to pass a list of messages, a list of messages that are identified by their of messages that are identified by their role and the message content. The role role and the message content. The role is the key new feature here. Then ## [00:16:44 - 00:17:17] is the key new feature here. Then we want to return we want to return the next the next the next message from the AI. This is going to message from the AI. This is going to have the role of assistant. So, we're have the role of assistant. So, we're going to going to going to return generally streaming token by return generally streaming token by token in a really nice sort of easy to token in a really nice sort of easy to read way an output, a response. So, read way an output, a response. So, we're going to do a request. We're going we're going to do a request. We're going to do a response. to do a response. So, this is a messagebased HTTP ## [00:17:17 - 00:17:48] So, this is a messagebased HTTP interface, very classic interface, very classic that all developers are familiar with. that all developers are familiar with. This is where OpenAI started and it's This is where OpenAI started and it's important to keep this in mind always important to keep this in mind always because it's it's just a natural because it's it's just a natural evolution of building software. OpenAI evolution of building software. OpenAI kind of codified it in this developer kind of codified it in this developer user assistant setup. So let's dig into user assistant setup. So let's dig into this chat style model syntax. Again, this chat style model syntax. Again, instead of just a list of content and a ## [00:17:48 - 00:18:20] instead of just a list of content and a list of messages, we have instead a role list of messages, we have instead a role that allows us to put in a list of chat that allows us to put in a list of chat messages with different roles. For messages with different roles. For instance, developer or user and then instance, developer or user and then output just another chat message. output just another chat message. And so we can we can see developer role, And so we can we can see developer role, we can see user role. And there's going we can see user role. And there's going to be three different roles in general to be three different roles in general as mentioned developer. Th this is as mentioned developer. Th this is setting the vibe. This is setting the setting the vibe. This is setting the highlevel instructional context. This is ## [00:18:20 - 00:18:52] highlevel instructional context. This is this is setting the behavior and the this is setting the behavior and the flavor of your LLM. This is where you flavor of your LLM. This is where you can do a lot of work. You can't really can do a lot of work. You can't really do much work on what the user puts in. do much work on what the user puts in. You can of course test it like you're a You can of course test it like you're a user and you can sort of act like the AI user and you can sort of act like the AI providing example outputs, but you can't providing example outputs, but you can't really take the place of the AI, the LLM really take the place of the AI, the LLM yourself. It it's going to be important yourself. It it's going to be important to really dial in your developer prompt, to really dial in your developer prompt, your system level prompt. And this is your system level prompt. And this is what we see in the OpenAI docs. Uh these ## [00:18:52 - 00:19:24] what we see in the OpenAI docs. Uh these are your instructions. These these are prioritized. These are the highlevel prioritized. These are the highlevel priority things that we're going to priority things that we're going to focus on first. The user is just focus on first. The user is just engaging. That's the user. The assistant engaging. The assistant is either generated directly by the is either generated directly by the model or could be examples that you model or could be examples that you provide. Now, also in 2023, provide. Now, also in 2023, OpenAI extended their chat completions OpenAI extended their Chat Completions API to a couple of different things. API to a couple of different things. They first came out with the function They first came out with the function calling API and this was pretty cool ## [00:19:24 - 00:19:56] calling API and this was pretty cool because because because they said they actually took the models they said they actually took the models and fine-tuned them to both detect when and fine-tuned them to both detect when a function needs to be called and to a function needs to be called and to respond with an appropriate JSON message respond with an appropriate JSON message that is going to allow us to call that that is going to allow us to call that function. function. and And this was pretty cool because this didn't this was pretty cool because this didn't really exist before. We could say, really exist before. We could say, "Please return JSON mode." And that kind "Please return JSON mode." And that kind of worked, ## [00:19:56 - 00:20:29] of worked, of worked, but it didn't work all the time. And so but it didn't work all the time. And so we actually had to fine-tune models to we actually had to fine-tune models to be really good at function calling. In be really good at function calling. In fact, a few months later, five months fact, a few months later, five months later in November, OpenAI released JSON later in November, OpenAI released JSON mode because of the very fact that this mode because of the very fact that this sort of more general JSON mode wasn't sort of more general JSON mode wasn't always working with a simple prompt. So, always working with a simple prompt. So, presumably this is another fine-tuned presumably this is another fine-tuned model. Now, importantly, while function model. Now, importantly, while function calling calling calling returns JSON mode, it's not the same as ## [00:20:29 - 00:21:01] returns JSON mode, it's not the same as JSON mode. JSON mode is going to be JSON mode. JSON mode is going to be useful outside of function calling. useful outside of function calling. and more generally, we can think about more generally, we can think about having a specific type of output, having having a specific type of output, having a structured output that we can know and a structured output that we can know and define and rely on. This is going to be define and rely on. This is going to be a key to building applications in the a key to building applications in the future. So if we go back to the big idea future. So if we go back to the big idea of request response, ## [00:21:01 - 00:21:31] of request response, we can think about tool and function we can think about tool and function calling very simply. It it introduced calling very simply. It it introduced this Chat Completions API introduced this Chat Completions API introduced first class tool and function calling first class tool and function calling as well as very nicely convenient as well as very nicely convenient structured outputs. So what we did is as structured outputs. So what we did is as the developer we're sort of providing the developer we're sort of providing some information to that fine-tuned some information to that fine-tuned model. We're providing a function get ## [00:21:32 - 00:22:03] model. We're providing a function get weather and we're sort of providing a weather and we're sort of providing a natural language unstructured input. natural language unstructured input. That model is then going to notice this That model is then going to notice this is asking for some function calling. is asking for some function calling. It's going to quickly change our It's going to quickly change our unstructured input into structured input unstructured input into structured input and I'm going to send back everything I and I'm going to send back everything I need to be able to on the developer on need to be able to on the developer on the app side not within the model now the app side not within the model now actually execute that function with the ## [00:22:03 - 00:22:35] actually execute that function with the appropriate format required as input to appropriate format required as input to the function which came out of the model the function which came out of the model that will then come back with some that will then come back with some structured output that we can convert structured output that we can convert back into unstructured conversational back into unstructured conversational flow with the user and we can finally flow with the user and we can finally get the response of oh you want to know get the response of oh you want to know the weather in Paris here's the weather the weather in Paris here's the weather in Paris in Paris in Paris now this function calling sort of ## [00:22:36 - 00:23:08] now this function calling sort of fivestep process here is non-trivial by fivestep process here is non-trivial by itself and It's really great that it's itself and It's really great that it's sort of totally baked in. And we've sort of totally baked in. And we've talked about this many times before. It's kind of reasoning and action in one It's kind of reasoning and action in one step. And there's all this good stuff. step. But what we want to kind of focus in on But what we want to kind of focus in on uh here to round out the chat uh here to round out the Chat Completions API discussion is we can completions API discussion is we can kind of look at um we're we're kind of look at um we're we're fundamentally leveraging some structured fundamentally leveraging some structured outputs here. We're fundamentally outputs here. We're fundamentally leveraging that JSON output. So all this leveraging that JSON output. So all this is contained in 2023 and only in 2025 I ## [00:23:08 - 00:23:38] is contained in 2023 and only in 2025 I think are people really starting to you think are people really starting to you know really like people that are are know really like people that are are just now getting into the field they're just now getting into the field they're starting to come into this with an starting to come into this with an agentic point of view where something agentic point of view where something like this is is quite important where like this is is quite important where we're calling tools and functions all we're calling tools and functions all the time. Uh, speaking of tools, this the time. Uh, speaking of tools, this was one of the key features added in the was one of the key features added in the OpenAI assistance API and OpenAI assistance API and this came out at the same time as that this came out at the same time as that JSON mode, at least V1 beta. V2 beta ## [00:23:38 - 00:24:09] JSON mode, at least V1 beta. V2 beta wasn't dropped until April 2024. And the assistance API is basically, look at assistance API is basically, look at this. this. It's going to be allow us to build AIS. We called them assistants at the time. Nobody kind of called them agents at Nobody kind of called them agents at that time. uh that uses OpenAI's models, that time. uh that uses OpenAI's models, access files, maintain persistent access files, maintain persistent threads and cool and call tools. So threads and cool and call tools. So we've got file retrieval RAG, we've got we've got file retrieval RAG, we've got tool calling tool calling kind of agents and we can define a ## [00:24:09 - 00:24:40] kind of agents and we can define a thread very simply. A thread is thread very simply. A thread is literally the convo between the literally the convo between the assistant and the user. It's just it's a assistant and the user. It's just it's a session. And so we can start to think session. And so we can start to think about this idea of a kind of session about this idea of a kind of session memory and beyond session memory and memory and beyond session memory and lots of kind of things at that time and lots of kind of things at that time and it was very simple how to use this. We it was very simple how to use this. We wanted to create our assistant. We wanted to create the thread to add wanted to create the thread to add messages just like Chat Completions API messages just like Chat Completions API and we wanted to run our assistant on and we wanted to run our assistant on that thread. Importantly, there were a ## [00:24:40 - 00:25:11] that thread. Importantly, there were a couple of key tools added and we'll see couple of key tools added and we'll see sort of, you know, echoes of this in the sort of, you know, echoes of this in the user interface today that we already user interface today that we already looked at. We had code interpreter, we looked at. We had code interpreter, we had retrieval or rag/file search, and we had retrieval or rag/file search, and we had function or tool calling. And so, we had function or tool calling. And so, we can kind of think about how a user wants can kind of think about how a user wants to interact with our assistant. In this to interact with our assistant. In this nice little image here, the user's nice little image here, the user's message, how much should I contribute to message, how much should I contribute to my retirement plan? This is the personal my retirement plan? This is the personal finance bot. uh you should contribute finance bot. uh you should contribute something something something based on ## [00:25:11 - 00:25:45] something something something based on all of these tool calls thread all of these tool calls thread conversation management um you know in conversation management um you know in the simplest case it's just sort of one the simplest case it's just sort of one function or tool call and I'm getting function or tool call and I'm getting back a specific response that helps me back a specific response that helps me out to answer the user's query. So I can out to answer the user's query. So I can kind of imagine the user only sees this kind of imagine the user only sees this in a similar way to how the classic chat in a similar way to how the classic Chat Completions API. The user only really completions API. The user only really sees this and really they don't even see ## [00:25:45 - 00:26:18] sees this and really they don't even see this. This is for us as developers. Uh, this. Uh, so we can really start to to root so we can really start to to root ourselves in what things were like ourselves in what things were like heading into 2025, heading into 2025, the year of agents, where the responses the year of agents, where the Responses API was released in March. And this was API was released in March. And this was released as part of the released as part of the new tools for building agents new tools for building agents release blog. And so this was part of release blog. And so this was part of the Agents SDK and ## [00:26:18 - 00:26:49] the Agents SDK and the Responses API was kind of the core the Responses API was kind of the core of it though of it though as they said in the release our new API as they said in the release our new API primitive for leveraging OpenAI built-in primitive for leveraging OpenAI built-in tools to build agents and they they go tools to build agents and they they go on to say that it combined the on to say that it combined the simplicity of chat completions with the simplicity of chat completions with the tool use capabilities of the assistance tool use capabilities of the assistance API. So now with the Responses API, with API. So now with the Responses API, with a single Responses API, call developers ## [00:26:50 - 00:27:21] a single Responses API, call developers can solve even more complex things, even can solve even more complex things, even more tool calls, function calls, even more tool calls, function calls, even more turns of the model, even more more turns of the model, even more conversation turns, even more threads, conversation turns, even more threads, even more sessions, even more stuff even more sessions, even more stuff because they they mentioned at the time, because they they mentioned at the time, and I mean this wasn't that long ago, and I mean this wasn't that long ago, right? This was 6 months ago. As model right? As model capabilities continue to evolve, we capabilities continue to evolve, we believe the Responses API will provide a believe the Responses API will provide a more flexible foundation uh for building more flexible foundation uh for building agentic applications. And during that ## [00:27:21 - 00:27:54] agentic applications. And during that release, they noted that there's even release, they noted that there's even more tools. One of which arguably, you more tools. One of which arguably, you know, should have been put in uh long know, should have been put in uh long time before, but web search, of course, time before, but web search, of course, is just a function calling of some is just a function calling of some potential web search tool like the SER potential web search tool like the SER API or Tavali like we we typically use API or Tavali like we we typically use in our classes. And then of course in our classes. And then of course there's the computer use stuff that we there's the computer use stuff that we will get into uh later in this series. will get into uh later in this series. So we can kind of see how all of this is ## [00:27:54 - 00:28:25] So we can kind of see how all of this is starting to come together starting to come together in the year of agents. So uh Whiz, I'd in the year of agents. So uh Whiz, I'd like to just have a quick discussion to like to just have a quick discussion to round out this Responses API piece. So round out this Responses API piece. So system user assistant. Oh, I'm sorry. I should say developer user assistant. This is the gold standard today. Is that right? right? Uh certainly when working with the Uh certainly when working with the Responses API, it's the only thing that Responses API, it's the only thing that exists. uh realistically uh you know if exists. uh realistically uh you know if you're using something like say ChatGPT OSS you're using something like say ChatGPT OSS uh which is you know the open source ## [00:28:25 - 00:28:57] uh which is you know the open source model which still uses the harmony model which still uses the harmony prompt template right uh which which is prompt template right uh which which is used used for the uh the Responses API used used for the uh the Responses API if you pass in a system prompt it just if you pass in a system prompt it just gets automatically converted to a gets automatically converted to a developer prompt on the back end. So developer prompt on the back end. So certainly for uh for our OpenAI models, certainly for uh for our OpenAI models, developer prompt is the is the one you developer prompt is the is the one you should be using. should be using. Okay. And if people go and they they Okay. And if people go and they they build stuff with open-source models, build stuff with open-source models, they're probably going to still see this they're probably going to still see this system user assistant language for quite ## [00:28:57 - 00:29:28] system user assistant language for quite some time, maybe some time, maybe forever. I mean, I forever is a long forever. I mean, I forever is a long time in the age of AI, but like this is time in the age of AI, but like this is specifically for OpenAI tooling today. specifically for OpenAI tooling today. It's not something that's seen broad It's not something that's seen broad adoption of the new terminology adoption of the new terminology throughout industry. throughout industry. Yeah, that's right. We haven't yet Yeah, that's right. We haven't yet harmonized on the uh on the on the harmonized on the uh on the on the harmony prompt format as an industry. harmony prompt format as an industry. However, people will say in their docs, However, people will say in their docs, we're using the OpenAI chat completions we're using the OpenAI Chat Completions API format and it will still not say ## [00:29:28 - 00:30:01] API format and it will still not say developer. It'll say system. So, developer. So, and I think this is an important piece, and I think this is an important piece, right? because we we do want to right? because we we do want to distinguish between the chat completions distinguish between the chat completions endpoints that we're we're kind of been endpoints that we're we're kind of been used to up till now and then the used to up till now and then the Responses API, right? The Responses API Responses API, right? The Responses API is a uh is is like a newer updated is a uh is is like a newer updated version of that chat completion, a version of that chat completion, a better a better version of the API and I better a better version of the API and I imagine we'll slowly see the industry imagine we'll slowly see the industry walk toward it. Uh it is a good format. walk toward it. It is useful. It helps us do stuff we It is useful. It helps us do stuff we care to do. uh but uh you know takes a ## [00:30:01 - 00:30:31] care to do. uh but uh you know takes a little while for for everything to to little while for for everything to to pick up. So uh for now you know pick up. So uh for now you know developer is what we want to think about developer is what we want to think about if we're in the OpenAI ecosystem most if we're in the OpenAI ecosystem most certainly over system prompt and okay certainly over system prompt and okay interestingly there is still a system interestingly there is still a system prompt of course right uh but the system prompt of course right uh but the system prompt now has has has moved up an prompt now has has has moved up an echelon of power right it's more echelon of power right it's more powerful powerful powerful and it's more aligned with what you'd and it's more aligned with what you'd expect a system product ## [00:30:32 - 00:31:04] expect a system product it's about the system. It's not about it's about the system. It's not about the interactions. It's about the system itself. Like when was it created? system itself. What day is it? What you know what is What day is it? What you know what is the model? These things that are that the model? These things that are that describe the actual system, right? As describe the actual system, right? As opposed to describing like some opposed to describing like some functionality that we desire or some functionality that we desire or some instructions that we want. So I I do instructions that we want. So I I do think actually the naming of the new think actually the naming of the new prompt as the developer prompt that's prompt as the developer prompt that's the prompt we the developer give to the ## [00:31:04 - 00:31:36] the prompt we the developer give to the model. I do think it makes more sense model. I do think it makes more sense uh from an intuitive perspective. uh from an intuitive perspective. Certainly the system prompt makes more Certainly the system prompt makes more sense when it describes the system. sense when it describes the system. That's right. Like when we go to system That's right. Like when we go to system settings on our Mac, you know. Yeah. settings on our Mac, you know. Okay. All right. So I I just I'd Yeah. So I I just I'd like to take a moment to just if we like to take a moment to just if we could just maybe wax poetical here for could just maybe wax poetical here for for a moment. Okay. So we can look back for a moment. So we can look back and we could say okay 2023 to 2025 and we could say okay 2023 to 2025 and we see the chat completions and it and we see the chat completions and it sort of took off and it gets this it sort of took off and it gets this it gets this you know great adoption by the ## [00:31:36 - 00:32:08] gets this you know great adoption by the industry sort of sets the gold standard industry sort of sets the gold standard and you know then then we come out with and you know then then we come out with this assistance API. I think everybody this assistance API. I think everybody was talking about virtual assistants at was talking about virtual assistants at the time right and then and then the time right and then and then the sort of new tools for building agents. sort of new tools for building agents. This is the Responses API. were sort of focused all about agents. Now everybody's calling the AIS agents, Now everybody's calling the AIS agents, not assistants. Um like what do you not assistants. Um like what do you notice when you look back over the last notice when you look back over the last couple of years? You know, from even couple of years? You know, from even pre-hat completions API uh from a pre-hat completions API uh from a developer perspective like what what ## [00:32:08 - 00:32:39] developer perspective like what what what are you taking away from, you know, what are you taking away from, you know, if we could just take a moment here just if we could just take a moment here just to consider? to consider? Yeah. What's worth taking away as we head into What's worth taking away as we head into this new paradigm and this new series? this new paradigm and this new series? Consider the following. Right. Classic Consider the following. Classic uh Bill Nye reference for you guys out uh Bill Nye reference for you guys out there. But but so like I I think of it there. I mean when we started uh our this way. I mean when we started uh our context window was a big blob we dump context window was a big blob we dump stuff in, right? It was like uh that's stuff in, right? It was like uh that's what it was. And we we did these things what it was. And we we did these things and we we we we came to the conclusion ## [00:32:39 - 00:33:11] and we we we we came to the conclusion that like well hey it turns out we have that like well hey it turns out we have this emergent behavior. And the emergent this emergent behavior. And the emergent behavior is if I tell the model to do behavior is if I tell the model to do stuff and then I ask a question, it'll stuff and then I ask a question, it'll like respect that first part during like respect that first part during during the second part, right? That's during the second part, right? That's pretty cool. pretty cool. Maybe we should train the model to be Maybe we should train the model to be like particularly good at that, right? like particularly good at that, right? And so now we move from this one blob to And so now we move from this one blob to like have two blobs. We got our system like have two blobs. We got our system our old school system prompt. We have our old school system prompt. We have our our user uh you know prompt. And then of course whatever the LLM uh ## [00:33:11 - 00:33:43] then of course whatever the LLM uh produces that can be our assistant produces that can be our assistant response or what whatever we want to response or what whatever we want to call it. call it. Yeah. And then we move forward right we we we And then we move forward right we we we learned more about how these tools are learned more about how these tools are being leveraged. So we're like oh well being leveraged. So we're like oh well they're people are using them to make they're people are using them to make JSON blobs to call Python functions. JSON blobs to call Python functions. We should like bake that in. That should We should like bake that in. That should be like part of the token sequences that be like part of the token sequences that we actually assign special meaning to we actually assign special meaning to during training. And then it was like, during training. And then it was like, oh well uh well well actually now the oh well uh well well actually now the assistance response ## [00:33:43 - 00:34:13] assistance response because we we have this new thing called because we we have this new thing called called uh you know reasoning models. The called uh you know reasoning models. The assistant's response is like we should assistant's response is like we should we should we shouldn't like give the we should we shouldn't like give the user the whole output just every time. user the whole output just every time. we should like allow the UI to we should like allow the UI to differentiate between those two things differentiate between those two things because these systems no longer exist in because these systems no longer exist in some vacuum where it's just it user some vacuum where it's just it user inputs and gets response. So inputs and gets response. So what it comes down to is as LMS have what it comes down to is as LMS have integrated into applications into our ## [00:34:14 - 00:34:45] integrated into applications into our application flows as we've designed application flows as we've designed systems that can be powered by LLMs systems that can be powered by LLMs we've therefore shifted uh the way that we've therefore shifted uh the way that we train models the way that we think we train models the way that we think about prompts uh in order to adapt more about prompts uh in order to adapt more uh or more suitably to that to that uh or more suitably to that to that paradigm. And I think that is like you paradigm. And I think that is like you can look at the evolution of prompts of can look at the evolution of prompts of prompt templates and it directly maps to prompt templates and it directly maps to the evolution of how we use these things the evolution of how we use these things and so it is it is very interesting. I and so it is it is very interesting. I do think it's a evolution that's ## [00:34:45 - 00:35:15] do think it's a evolution that's important. I this is certainly not the important. I this is certainly not the end of the road. Right. That's right. end of the road. But for now it's a nice little map of But for now it's a nice little map of kind of how we got here uh and what kind of how we got here uh and what and what we think to do. Right. We we and what we think to do. We we have like the channels as part of the have like the channels as part of the responses or harmony format, right? And responses or harmony format, right? And those channels are not the model itself those channels are not the model itself has no there's no use at all for those, has no there's no use at all for those, right? Like the model itself has no but right? Like the model itself has no but but in an application but in an application they're extremely important and we can they're extremely important and we can leverage them to great effect. And this ## [00:35:15 - 00:35:47] leverage them to great effect. And this is the idea. The model is no longer just is the idea. The model is no longer just built for this raw built for this raw inter. It's it's built with in mind that inter. It's it's built with in mind that this sits in an application of some kind this sits in an application of some kind and these applications have needs uh you and these applications have needs uh you know like being able to differentiate know like being able to differentiate who sees what being able to who sees what being able to differentiate you know what instruction differentiate you know what instruction means what and I I think this is a a means what and I I think this is a a great great great example of how we've adapted this big example of how we've adapted this big general technology to be a little bit general technology to be a little bit better suited for what we're actually better suited for what we're actually doing with big technology. ## [00:35:47 - 00:36:19] doing with big technology. Yeah. and a little bit more, Yeah. and a little bit more, you know, not to anthropomorphize, but you know, not to anthropomorphize, but like like the way we have chats with like like the way we have chats with each other, right? Like we don't hold each other, right? Like we don't hold every single word that was just said in every single word that was just said in our active memory and context. That's our active memory and context. That's dumb, right? It's like the people that dumb, right? It's like the people that just repeat back exactly what you just just repeat back exactly what you just said, like very annoying, right? and said, like very annoying, right? and and I I think there's also this real and I I think there's also this real interesting sort of almost alignment to interesting sort of almost alignment to you know the way like these models and ## [00:36:19 - 00:36:51] you know the way like these models and these apps we're building they are being these apps we're building they are being built to solve problems for real people. built to solve problems for real people. So you know on some level we want it to So you know on some level we want it to get in there and kind of act like we get in there and kind of act like we would expect it to while it's solving would expect it to while it's solving that problem. Okay. So that problem. So exactly. exactly. So as we get into uh developer prompting So as we get into uh developer prompting of GPT-4o, I just want to double back for of GPT-4o, I just want to double back for a second. There seems to be some uh a second. There seems to be some uh confusion in the chat on this. Okay. So confusion in the chat on this. So when we say system prompt, when we say system prompt, basically this is the OpenAI owns the ## [00:36:51 - 00:37:22] basically this is the OpenAI owns the system, runs the system. They get to system, runs the system. They get to decide on the system prompt. We do not. decide on the system prompt. We are developing with their system. Therefore, we're using the developer Therefore, we're using the developer thing. This is not to be confused with thing. This is not to be confused with the harmony format. We've gone into the harmony format. We've gone into detail on that in another event. Check detail on that in another event. Check out GPTOSS on our YouTube channel. We can override the system prompt or We can override the system prompt or certain fields of it that that they have certain fields of it that that they have made available to us. So, we can do made available to us. So, we can do things like update what the time is. ## [00:37:22 - 00:37:54] can do things like update what the model should be called. Uh the these kinds of should be called. Uh the these kinds of things are exposed to us, but certainly things are exposed to us, but certainly it's more meant for the uh the builders it's more meant for the uh the builders or deployers of the model. or deployers of the model. Okay. and um and um and um we'll add potential entire event on we'll add potential entire event on system prompt to the maybe list. Okay, system prompt to the maybe list. Okay, thanks Wiz. All right, here we go. Just thanks Wiz. Just for you, Manny. Okay, developer for you, Manny. Okay, developer prompting of GPT-4o. So, I want to just prompting of GPT-4o. So, I want to just take you back for a moment uh to take you back for a moment uh to February of 2019, GPT2 was released, the ## [00:37:54 - 00:38:24] February of 2019, GPT2 was released, the last open source before GPTOSS from last open source before GPTOSS from OpenAI. And we saw that these things, OpenAI. And we saw that these things, these models they could learn without these models they could learn without any explicit supervision, which means any explicit supervision, which means without any finetuning, without any finetuning, which means they could do it simply by which means they could do it simply by prompting. prompting. Now we came to to sort of understand Now we came to to sort of understand prompting as prompt engineering maybe to prompting as prompt engineering maybe to ditch the engineering later and now ditch the engineering later and now everybody uh even average users are everybody uh even average users are prompting and now maybe the engineers ## [00:38:24 - 00:38:55] prompting and now maybe the engineers are doing more prompt engineering. This are doing more prompt engineering. This is simply giving the LM instructions in is simply giving the LM instructions in the context window. that is it it's the context window. that is it it's leveraging in context learning which of leveraging in context learning which of course is an idea put forth in the GPT3 course is an idea put forth in the GPT3 paper um this famous chart showing that paper um this famous chart showing that with just one example put in context with just one example put in context oneshot learning and then two three four oneshot learning and then two three four five six 32 shot learning with for five six 32 shot learning with for bigger models uh we can get very very ## [00:38:55 - 00:39:26] bigger models uh we can get very very good results this is the GBT3 good results this is the GBT3 learning from in the GBT3 paper learning from in the GBT3 paper in May 2020. Now, since then, we've kind in May 2020. Now, since then, we've kind of codified a number of prompt of codified a number of prompt engineering best practices. We want to engineering best practices. We want to be clear and specific in the be clear and specific in the instructions we put in context. We also instructions we put in context. We also used to talk about sort of providing used to talk about sort of providing some context, you know, providing a some context, you know, providing a role, providing a persona, providing a role, providing a persona, providing a flavor, a vibe, a sort of place to flavor, a vibe, a sort of place to stand. ## [00:39:26 - 00:39:59] stand. And this role or persona oftent times as And this role or persona oftent times as we saw in the early days was something we saw in the early days was something like you are a helpful assistant um or like you are a helpful assistant um or we might be doing some evaluation and we we might be doing some evaluation and we might you know say you know you're a might you know say you know you're a teacher grading a quiz. This kind of teacher grading a quiz. This kind of role persona has obviously been expanded role persona has obviously been expanded on to great effect and to great degree on to great effect and to great degree in the years since. And when we talk in the years since. And when we talk about giving inputs, we can sort of use about giving inputs, we can sort of use the user assistant user assistant input ## [00:39:59 - 00:40:29] the user assistant user assistant input output setup providing some examples in output setup providing some examples in context. Uh this might be called fshot context. Uh this might be called fshot learning. In fact, language models are learning. In fact, language models are fshot learners is the title of that fshot learners is the title of that original paper. Uh moreover, we see a original paper. Uh moreover, we see a lot of be work being done today on this lot of be work being done today on this chain of thought thing. Now we used to chain of thought thing. Now we used to at a high level tell all these kind of at a high level tell all these kind of system prompts and models think through system prompts and models think through step by step and this was a prompt step by step and this was a prompt engineering best practice born of the ## [00:40:29 - 00:41:01] engineering best practice born of the chain of thought paper chain of thought paper and this kind of series of intermediate and this kind of series of intermediate reasoning steps that we thought was so reasoning steps that we thought was so useful so powerful put a pin in that for useful so powerful put a pin in that for a moment and then moreover the output of a moment and then moreover the output of course we talked about JSON quite a bit course we talked about JSON quite a bit today already that format being dialed today already that format being dialed is important. And so is important. And so perhaps perhaps perhaps we've learned since that prompt we've learned since that prompt engineering is actually only a subset of engineering is actually only a subset of the larger context engineering. And you ## [00:41:01 - 00:41:32] the larger context engineering. And you know since uh DEX put forth this new know since uh DEX put forth this new term the industry has really adopted it term the industry has really adopted it and it it probably calls for a revamp and it it probably calls for a revamp and revisit of what we think of as the and revisit of what we think of as the best practices of prompt engineering or best practices of prompt engineering or I should say of context engineering I should say of context engineering because if we look deeply at this kind because if we look deeply at this kind of circle we see things like state or of circle we see things like state or history things like memory of course history things like memory of course structured outputs RAG all of this is structured outputs RAG all of this is included in context engineering. So, ## [00:41:32 - 00:42:03] included in context engineering. So, it's not just prompts, it's not just it's not just prompts, it's not just instructions, it's also instructions, it's also stuff the LM wasn't trained on, it's stuff the LM wasn't trained on, it's also using tools and calling functions. also using tools and calling functions. And remember, when we got the responses And remember, when we got the Responses API released, it's it's talking about as API released, it's it's talking about as model capabilities continue to evolve, model capabilities continue to evolve, this will provide the more flexible this will provide the more flexible foundation. And so, what do we mean when foundation. And so, what do we mean when we say model capabilities have continued we say model capabilities have continued to evolve? Well, if we consider the four ## [00:42:03 - 00:42:34] to evolve? Well, if we consider the four primary best practices of prompt primary best practices of prompt engineering, we've kind of added this engineering, we've kind of added this part that makes the agent good, the part that makes the agent good, the agentic reasoning, the reasoning piece, agentic reasoning, the reasoning piece, the searching and researching. When the searching and researching. When I go and I find a bunch of stuff and I I go and I find a bunch of stuff and I need to put it back in context, and I need to put it back in context, and I find other stuff and I want to put it find other stuff and I want to put it back in context, how am I doing that? Am back in context, how am I doing that? Am I just dumping everything I find on I just dumping everything I find on every web page back into context? As we every web page back into context? As we just sort of alluded to, like, uh, no. And moreover, it's not just reasoning And moreover, it's not just reasoning during an agentic search. ## [00:42:34 - 00:43:05] during an agentic search. It's also reasoning in terms of well, It's also reasoning in terms of well, how do I even decide or reason when to how do I even decide or reason when to select a reasoning or non-reasoning select a reasoning or non-reasoning model? Um, some of this stuff we don't model? Um, some of this stuff we don't have access to exactly the way OpenAI have access to exactly the way OpenAI might decide on auto versus instant or might decide on auto versus instant or thinking. thinking. But all this kind of leads to August 7th But all this kind of leads to August 7th last month GPT-4o came out and OpenAI last month GPT-4o came out and OpenAI released the GPT-4o released the GPT-4o prompting guide prompting tips to prompting guide prompting tips to maximize the quality of model outputs ## [00:43:05 - 00:43:36] maximize the quality of model outputs derived from all of our great derived from all of our great experience. Now there's this interesting experience. Now there's this interesting idea that they talked about which is idea that they talked about which is called agentic workflow predictability. called agentic workflow predictability. First of all, if adopting GPT-4o for First of all, if adopting GPT-4o for agentic and tool calling flows, we agentic and tool calling flows, we recommend Responses API off the cuff recommend Responses API off the cuff where reasoning is persisted between where reasoning is persisted between tool calls. That's very interesting. tool calls. There's a lot of uh nuanced agentic There's a lot of uh nuanced agentic things we want to keep in mind. For ## [00:43:36 - 00:44:08] things we want to keep in mind. For instance, there's this idea of of instance, there's this idea of of eagerness of agentic eagerness. So we eagerness of agentic eagerness. So we can think of our can think of our agent application architectures, these agent application architectures, these agentic scaffolds as being able to span agentic scaffolds as being able to span a very wide spectrum of control. a very wide spectrum of control. And we've talked about this before on And we've talked about this before on this channel talking about workflows this channel talking about workflows versus agents. Uh but essentially some versus agents. Uh but essentially some systems you might want to delegate the systems you might want to delegate the vast majority of decision-m to the model ## [00:44:08 - 00:44:39] vast majority of decision-m to the model while others not so much. you don't while others not so much. you don't really want to give the model that kind really want to give the model that kind of autonomy, that sort of agency. of autonomy, that sort of agency. You might want to make it more of a You might want to make it more of a programmatic workflow or even put a programmatic workflow or even put a human in the loop. Now, there's a lot to human in the loop. Now, there's a lot to this guide and so Whiz, I'd love for you this guide and so Whiz, I'd love for you to just comment on this and we'll we'll to just comment on this and we'll we'll encourage everybody to read this on encourage everybody to read this on their own following the demo today and their own following the demo today and our introductory session. But there's our introductory session. But there's things like agentic eagerness, tool ## [00:44:39 - 00:45:10] things like agentic eagerness, tool preamles, taking tool calls and tool preamles, taking tool calls and tool descriptions to the next level. Um, not descriptions to the next level. Um, not just reasoning or non, but low, medium, just reasoning or non, but low, medium, high reasoning. Uh and then of course high reasoning. Uh and then of course there's this idea of sort of there's this idea of sort of transmitting context and memory sort of transmitting context and memory sort of more selectively uh across conversation more selectively uh across conversation threads or between different agents or threads or between different agents or uh between different models within one uh between different models within one conversation or maybe meta conversation conversation or maybe meta conversation is the right word here. Um how do you is the right word here. Um how do you see prompting changing in today's ## [00:45:10 - 00:45:40] see prompting changing in today's paradigm versus a chat completions paradigm versus a chat completions paradigm? paradigm? It's just a lot more effort that's It's just a lot more effort that's needed to kind of lock in these like needed to kind of lock in these like golden prompts, right? And I mean this golden prompts, right? And I mean this is there's a number of ways you can is there's a number of ways you can approach this. There's a number of ways approach this. There's a number of ways you can think about this. We're going to you can think about this. We're going to talk about one of the ways we can do talk about one of the ways we can do this uh you know in the demo, but I mean this uh you know in the demo, but I mean at the end of the day uh at the end of the day uh the prompt is like more powerful now the prompt is like more powerful now to use like just kind of like meme ## [00:45:40 - 00:46:11] to use like just kind of like meme language, right? like the like the in language, right? like the like the in the model is better at instruction the model is better at instruction following. It's better at following more following. It's better at following more complex instructions. It's better at so complex instructions. It's better at so many different things that that you know many different things that that you know we we used to have to kind of work we we used to have to kind of work around and now we don't have to. It's around and now we don't have to. It's way better at handling like this big way better at handling like this big glut of context, right? So for all of glut of context, right? So for all of these reasons, uh you know, it it it these reasons, uh you know, it it it allows us to be more versatile. It allows us to be more versatile. It allows us to to produce better ## [00:46:11 - 00:46:41] allows us to to produce better applications, but it comes at the cost applications, but it comes at the cost of of more effort. I mean, you know, of of more effort. I mean, you know, there's there's a lot of ways that we there's there's a lot of ways that we can think about prompting and how to can think about prompting and how to optimize prompting and should we use optimize prompting and should we use processes like disp, you know, go to the processes like disp, you know, go to the kind of automated prompt optimization kind of automated prompt optimization through some kind of framework or should through some kind of framework or should we just be like handcrafting, tinkering, we just be like handcrafting, tinkering, uh, you know, uh, prompt diffing. Uh, uh, you know, uh, prompt diffing. Uh, all all these questions are are great, all all these questions are are great, but at the end of the day, what it comes but at the end of the day, what it comes down to is the prompt is able to do ## [00:46:41 - 00:47:11] down to is the prompt is able to do more. It is therefore more complex. is more. is therefore going to be more important to therefore going to be more important to nail. Uh there's some fuzziness here nail. Uh there's some fuzziness here where it's easier to nail. where it's easier to nail. Yeah. Because it follows instructions so good, Because it follows instructions so good, right? But uh at the end of the day, the right? But uh at the end of the day, the way that you're constructing prompts has way that you're constructing prompts has to change. The way you think about to change. The way you think about prompting the machine has to change. prompting the machine has to change. G Open does a great job, by the way, G Open does a great job, by the way, telling you how to do this like telling you how to do this like quoteunquote best. quoteunquote best. Yeah. So there there's it's not like you ## [00:47:12 - 00:47:42] Yeah. So there there's it's not like you have to guess uh you know but uh you do have to guess uh you know but uh you do have to read it you do have to become have to read it you do have to become familiar with how to prop this beast familiar with how to prop this beast right uh just part of the learning curve right uh just part of the learning curve of these models now of these models now yeah it's it's almost like prompt yeah it's it's almost like prompt engineer is becoming like a real job or engineer is becoming like a real job or something right like like like as as the something right like like like as as the as the sort of system architecture as the sort of system architecture complexity uh sort of expands and the complexity uh sort of expands and the importance of the prompt to guide ## [00:47:42 - 00:48:14] the importance of the prompt to guide that, the developer prompt to guide the that, the developer prompt to guide the whole thing and keep it on relative whole thing and keep it on relative rails becomes sort of a an art in and of rails becomes sort of a an art in and of itself. Like it's it's like uh prompt itself. Like it's it's like uh prompt engineering is not what it once was. Um engineering is not what it once was. Um and uh maybe we need a new word for it, and uh maybe we need a new word for it, but it it's more important than ever, but it it's more important than ever, right? right? It is that. Yes, it is. It prompting hasn't become less important prompting hasn't become less important over time, right? Uh and I think this is ## [00:48:14 - 00:48:46] over time, right? Uh and I think this is like a trap people can fall into because like a trap people can fall into because the model is so much better. It's going the model is so much better. It's going to like take up, you know, the slack to like take up, you know, the slack or whatever of our prompts, but in or whatever of our prompts, but in reality, it just means we're leaving reality, it just means we're leaving more on the table. Uh it it it we're more on the table. Uh it it it we're we're leaving this uh this potentially we're leaving this uh this potentially very powerful thing on the table. Great very powerful thing on the table. Great great question in chat is like how is great question in chat is like how is this manifested right programmatically this manifested right programmatically right uh right uh right uh by a prompt mage. Yeah by a prompt mage. Yeah I mean easily by a prompt mage. Yeah I mean easily like the program part the building ## [00:48:46 - 00:49:17] like the program part the building of the system part is not the is not of the system part is not the is not where the artistry and where the artistry and engineering needs to occur. It's very engineering needs to occur. It's very straightforward. There are parameters straightforward. There are parameters that we can tap into that help us do that we can tap into that help us do this. It's combining these things in a this. It's combining these things in a way that works really well. that that way that works really well. that that that is where this this artistry exists. Okay. All right. Well, I think we've uh Okay. Well, I think we've uh we've yapped enough today. It's time to we've yapped enough today. It's time to get to the demo. Whiz, you're going to get to the demo. Whiz, you're going to show us what we need to know to be able show us what we need to know to be able to build the core of what will become ## [00:49:17 - 00:49:50] to build the core of what will become our very own AI Makerspace ChatGPT using our very own AI Makerspace ChatGPT using the Responses API. Uh take it away. It's the Responses API. It's yours. yours. All right. So this is going to be a very All right. So this is going to be a very brief introduction to the OpenAI brief introduction to the OpenAI Responses API. Uh we're not going to Responses API. Uh we're not going to talk about how to you know add web talk about how to you know add web search or anything like this. This is search or anything like this. This is this is coming down the pipeline. We're this is coming down the pipeline. We're just going to talk about how we can just going to talk about how we can actually use the real Responses API and actually use the real Responses API and how it's different. So we have of course how it's different. So we have of course a collab for this. Uh you know we have ## [00:49:50 - 00:50:21] a collab for this. Uh you know we have to pass in OpenAI API key classic. We to pass in OpenAI API key classic. We have to inst instantiate a client have to inst instantiate a client classic. This client is going to be how classic. This client is going to be how we effectively power Chad ChatGPT, right? Uh we effectively power Chad ChatGPT, right? Uh because this is the client that lets because this is the client that lets us have access to all the fun models us have access to all the fun models we'll eventually be stapling together. we'll eventually be stapling together. And of course, you can just use it. Uh we we know this. We've done this before. Uh you know, you tell the model, you ask Uh you know, you tell the model, you ask it a question, you get a response. it a question, you get a response. Hopefully this is not uh hopefully this ## [00:50:21 - 00:50:53] Hopefully this is not uh hopefully this is not not new stuff. Uh things we get is not not new stuff. Uh things we get because we are living in the reasoning because we are living in the reasoning world though or access to things like world though or access to things like the uh reasoning efforts of low, medium, the uh reasoning efforts of low, medium, high and secretly minimal. Uh the idea high and secretly minimal. Uh the idea here being right we get to tell our uh here being right we get to tell our uh Responses API like how much effort Responses API like how much effort should we put into thinking. Uh and should we put into thinking. Uh and though the names are kind of loosely though the names are kind of loosely defined, their function is is clear. Low defined, their function is is clear. Low uh you know, medium and high. You ## [00:50:53 - 00:51:24] uh you know, medium and high. You can expect that you'll get more can expect that you'll get more reasoning tokens produced with high than reasoning tokens produced with high than you would with medium than you would you would with medium than you would with low. Uh then we have instructions. with low. Instructions Instructions are are are like the developer prompt. Now this is like the developer prompt. Now this is this is a mind trip uh because of course this is a mind trip uh because of course instructions instructions uh are only going to be applied to uh are only going to be applied to exactly this what you see here response. exactly this what you see here response. We alternatively have of course the ## [00:51:24 - 00:51:54] We alternatively have of course the developer role. Now the developer role developer role. Now the developer role you'll notice is going to be taken into you'll notice is going to be taken into consideration for as long as we continue consideration for as long as we continue to include it in our quote unquote to include it in our quote unquote memory or our chat history. So the way memory or our chat history. So the way I'd encourage people to think about this I'd encourage people to think about this is for like oneoff instructions we use is for like oneoff instructions we use the instructions for uh an instruction the instructions for uh an instruction we wish to persist across the entire we wish to persist across the entire user interaction we're going to use the user interaction we're going to use the developer role right so instructions are developer role right so instructions are oneoff developer role stays for as long ## [00:51:54 - 00:52:24] oneoff developer role stays for as long as we keep showing the llmit there you as we keep showing the llmit there you go very cool okay then of course also we go very cool okay then of course also we ask it to talk like a wizard it does ask it to talk like a wizard it does talk like a wizard you get it okay there talk like a wizard you get it okay there we go we've seen this before structure we go we've seen this before structure ed responses. This is extremely ed responses. This is extremely important. This is a lot of how the important. This is a lot of how the world works right now, right? So when we world works right now, right? So when we ask it uh you know, hey, extract the ask it uh you know, hey, extract the event information and then we say Alice event information and then we say Alice and Bob are going to the AI engineering and Bob are going to the AI engineering boot camp kickoff on September 9th at 7 boot camp kickoff on September 9th at 7 p. m. Uh totally unrelated to what we're ## [00:52:24 - 00:52:56] p. m. Uh totally unrelated to what we're doing here, but registration for that doing here, but registration for that closes Tuesday, September 9th at noon closes Tuesday, September 9th at noon Eastern Daylight Time. Uh Eastern Daylight Time. Uh pardon the plug. Uh you'll notice that pardon the plug. Uh you'll notice that we want it extracted in this format. we want it extracted in this format. You'll notice as well this is just a You'll notice as well this is just a pyantic model and we can just pass it in pyantic model and we can just pass it in to our Responses API and we get out a to our Responses API and we get out a formatted uh response with those fields formatted uh response with those fields filled. Right? This is the kind of thing filled. This is the kind of thing that really allows us to make sure we're that really allows us to make sure we're thinking about things like state that ## [00:52:56 - 00:53:27] thinking about things like state that we're thinking about things like how we we're thinking about things like how we can use this in an application. Again, can use this in an application. Again, when we talk about these systems when we talk about these systems settling into an application, this is settling into an application, this is exactly what we mean. And then, of exactly what we mean. And then, of course, uh it's not just text, right? course, uh it's not just text, right? All of the models are omniodels, uh All of the models are omniodels, uh which means that they they take in which means that they they take in images as well. So, we can ask things images as well. So, we can ask things like describe the visual appearance of like describe the visual appearance of the people in this image, these guys. Uh the people in this image, these guys. Uh you know, let's see let's see what it you know, let's see let's see what it says. A person on the left, adult man, says. A person on the left, adult man, light complexion, short hair, face, light complexion, short hair, face, stubble. First on the right, adult man ## [00:53:27 - 00:53:58] stubble. First on the right, adult man with hair pulled back in a short goatee with hair pulled back in a short goatee mustache. I'll take it. mustache. Okay. Uh, this is the idea though, Okay. Uh, this is the idea though, right? It's not just text anymore. Now right? Now it's also images. No one, you know, how it's also images. No one, you know, how many times have you been in this many times have you been in this situation? The terminal situation? The terminal gives you an error. You're not going to gives you an error. You're not going to copy and paste the text. You're just copy and paste the text. You're just going to screenshot the error and throw going to screenshot the error and throw it in ChatGPT. Right? Uh, I know that it in ChatGPT. Uh, I know that in our class that's a favored pattern of in our class that's a favored pattern of people. Uh and so this is the uh this is ## [00:53:58 - 00:54:28] people. Uh and so this is the uh this is the way we can do it. This is the way the way we can do it. This is the way we're going to wind up building it out. we're going to wind up building it out. And then streaming, we all know And then streaming, we all know streaming, but also streaming of streaming, but also streaming of structured responses. So when we have structured responses. So when we have this base model and we ask the model to this base model and we ask the model to I think I think it's still going. Yeah. I think I think it's still going. Uh you'll you'll be able to see that Uh you'll you'll be able to see that it's actually going to spit out in it's actually going to spit out in order, right? It's going to give us in order, right? It's going to give us in order these fields, which means that we order these fields, which means that we can start work right away, right? If we can start work right away, right? If we want a trigger event uh to happen as want a trigger event uh to happen as soon as a field is done like let's say ## [00:54:28 - 00:55:00] soon as a field is done like let's say attributes right we don't have to wait attributes right we don't have to wait for the rest of the response we can for the rest of the response we can automatically start that process and automatically start that process and that's going to mean our application that's going to mean our application feels more responsive feels better to feels more responsive feels better to use uh and uh users will be big happy use uh and uh users will be big happy all of this is just the Responses API all of this is just the Responses API and then of course if you really miss 40 and then of course if you really miss 40 here are some settings that get you a here are some settings that get you a feeling of 40 back we put the reasoning feeling of 40 back we put the reasoning effort to minimal and we put the effort to minimal and we put the verbosity to the low and the model verbosity to the low and the model despite being GBD5 feels more for OE. Uh ## [00:55:00 - 00:55:32] despite being GBD5 feels more for OE. Uh so if you really missed it, if you're so if you really missed it, if you're really sad about it, this is a way you really sad about it, this is a way you can recreate it with the API thanks to can recreate it with the API thanks to the Responses API. Secondly, we have the Responses API. Secondly, we have this. This is our uh prompt optimizer this. This is our uh prompt optimizer for ChatGPT uh 5. So OpenAI produced this. for ChatGPT uh 5. It's a good resource. Uh, basically the It's a good resource. Uh, basically the idea here is that it lets you take this idea here is that it lets you take this original prompt. You are helpful original prompt. You are helpful assistant. You encourage people to be assistant. You encourage people to be their best selves. You are nice and not their best selves. You are nice and not rude. You have are a bombastic rude. You have are a bombastic personality. You can click optimize and personality. You can click optimize and it gives you something that's going to it gives you something that's going to work a little bit better with the model, ## [00:55:32 - 00:56:02] work a little bit better with the model, right? You can use feedback to uh to you right? You can use feedback to uh to you know, you can use this prompt template. know, you can use this prompt template. So, we can say make it so it's bombastic So, we can say make it so it's bombastic though and we can have that included in though and we can have that included in our prompt. Right? This is part of the our prompt. This is part of the prompting guide with things like meta prompting guide with things like meta prompting, right? So the chat GPT-4o is prompting, right? So the chat GPT-4o is good at making prompts for GPT-4o. This is good at making prompts for GPT-4o. This is something we should exploit the heck out something we should exploit the heck out of, right? Uh if we want the best of, right? Uh if we want the best prompts, we should use the model to help prompts, we should use the model to help us make the best prompts. Uh as well, ## [00:56:02 - 00:56:33] us make the best prompts. Uh as well, the prompting guide gives you a ton of the prompting guide gives you a ton of information about how to maximize what information about how to maximize what you need to do. You're going to notice you need to do. You're going to notice this pattern right uh of uh of XML this pattern right uh of uh of XML instead of JSON. Very nice uh very very instead of JSON. Very nice uh very very useful uh very good way to start using useful uh very good way to start using these prompts. If you take one like these prompts. If you take one like prompting tip from the guide, it's prompting tip from the guide, it's please use XML, right? It's just better please use XML, right? It's just better than than uh than than using a markdown than than uh than than using a markdown format for your prompts. And that's format for your prompts. And that's that's about it. I mean this is the ## [00:56:33 - 00:57:03] that's about it. I mean this is the engine that's going to drive eventually engine that's going to drive eventually our experience of our own homebrewed our experience of our own homebrewed ChatGPT right everything through this ChatGPT right everything through this client and most things through that client and most things through that Responses API this is how we get to Responses API this is how we get to tools this is how we get to uh you know tools this is how we get to uh you know things like web search this is how we things like web search this is how we get to things like agents all of it is get to things like agents all of it is going to be powered by this this nice going to be powered by this this nice little core uh right here uh there you little core uh right here uh there you go uh we're here every Wednesday please go uh we're here every Wednesday please like and subscribe and hit the bell like and subscribe and hit the bell notification. We love doing these ## [00:57:03 - 00:57:34] notification. We love doing these events. We're going to do a lot of these events. Uh and so, uh excited to do those ones. And with that, I'll send for you guys. And with that, I'll send you back to uh to Greg. you back to uh to Greg. All right, Whiz. So, we've got um quick All right, Whiz. So, we've got um quick wrap to do, but first, since we don't wrap to do, but first, since we don't really have a ton of time and we don't really have a ton of time and we don't have a ton of questions in the chat here have a ton of questions in the chat here for the next event, uh what do people for the next event, uh what do people have to look forward to? They've got RAG have to look forward to? They've got RAG and connectors. And so the way that this and connectors. And so the way that this is going to in interface with the is going to in interface with the Responses API, can you give us a quick ## [00:57:34 - 00:58:04] Responses API, can you give us a quick flavor for that? flavor for that? Uh I don't I don't think so. No. Easy. Yeah. So we're going to break down RAG from So we're going to break down RAG from first principles and then we're going to first principles and then we're going to talk to people about how to exactly talk to people about how to exactly integrate the things they see on the integrate the things they see on the user interface user interface but on the back end first. but on the back end first. That's right. Yes. I I think the idea is That's right. I I think the idea is that this Responses API is like the it's ## [00:58:04 - 00:58:36] that this Responses API is like the it's like the entry point like the entry point and its depth is overwhelming. and its depth is overwhelming. Right. So, uh, we we're we're gonna get Right. So, uh, we we're we're gonna get into it, but we're gonna we're gonna into it, but we're gonna we're gonna we're going to ease ourselves in so that we're going to ease ourselves in so that we're not we're not we're not seeing 7,000 new APIs per event. We want seeing 7,000 new APIs per event. We want to make sure that we're uh, you know, to make sure that we're uh, you know, we're doing this in a way where we can we're doing this in a way where we can leave being able to build each leave being able to build each component, right? But by itself, so that component, right? But by itself, so that it's it's useful for you even if you it's it's useful for you even if you never watch a different event, which we never watch a different event, which we hope you do. hope you do. That's right. And so if if people have That's right. And so if if people have questions about going deeper on things, ## [00:58:36 - 00:59:07] questions about going deeper on things, please smash the chat. Smash the YouTube please smash the chat. Smash the YouTube comments. We know Manny wants a system comments. We'll see if anybody else prompt event. We'll see if anybody else cares. Uh shout out to to Manny and the cares. Uh shout out to to Manny and the whole crew for joining us today. Thanks, whole crew for joining us today. Thanks, Whiz. I'm gonna go ahead and wrap up Whiz. Okay, guys. Uh thank you so much today. Uh thank you so much for for joining us and for joining Whiz for for joining us and for joining Whiz for his demo of the Responses API. Today for his demo of the Responses API. Today we learned we learned we learned about the history of the Responses API about the history of the Responses API from chat completions through function ## [00:59:07 - 00:59:39] from chat completions through function calling JSON mode through the switch calling JSON mode through the switch over to developer from system user over to developer from system user assistant adding tools in the assistance assistant adding tools in the assistance API adding even more tools more agentic API adding even more tools more agentic stuff in the Responses API and we will stuff in the Responses API and we will continue this series from here remember continue this series from here remember prompt engineering is dead long live prompt engineering is dead long live prompt engineering I guess I should call prompt engineering I guess I should call it context engineering ing now. Um, stay it context engineering ing now. Um, stay in buzzword compliance, everybody. It turns out prompting is more important turns out prompting is more important than ever, and it's slightly different than ever, and it's slightly different and more nuanced than ever. ## [00:59:39 - 01:00:11] and more nuanced than ever. Uh, that doesn't mean you should go out Uh, that doesn't mean you should go out and try to get a prompt engineer job and try to get a prompt engineer job tomorrow, though. So, thanks so much for tomorrow, though. So, thanks so much for joining us for this event at AI Maker joining us for this event at AI Maker Space. We're here every Wednesday. Uh, Space. Uh, next week we're covering part two. And if you're still with us on the stream, if you're still with us on the stream, I'd like you to know that we are on a I'd like you to know that we are on a mission to create the world's leading mission to create the world's leading community for people like you who want community for people like you who want to build, ship, and share production LLM to build, ship, and share production LLM applications. Our Discord and our events applications. Our Discord and our events are filled with really cool, really ## [01:00:11 - 01:00:43] are filled with really cool, really competent AI engineers, data scientists, competent AI engineers, data scientists, and tinkerers. So come join us in the and tinkerers. So come join us in the space. If you are looking to accelerate space. If you are looking to accelerate your LLM application development, we your LLM application development, we have one more cohort before the end of have one more cohort before the end of the year. It's cohort 8 and it kicks off the year. next Tuesday. It's going to be a banger. And uh if It's going to be a banger. And uh if you're looking to upskill, you're you're looking to upskill, you're looking to hit the ground running in looking to hit the ground running in 2026, 2026, 2026, this can get you where you want to go in ## [01:00:43 - 01:01:14] this can get you where you want to go in a really communityupported a really communityupported accountable environment that so many accountable environment that so many learners need. If not, just keep joining learners need. If not, just keep joining our how to build ChatGPT live streams our how to build ChatGPT live streams and you'll get where you're trying to go and you'll get where you're trying to go in no time. in no time. And with that, thanks so much for And with that, thanks so much for joining us for another weekly Wednesday joining us for another weekly Wednesday event. We'll see you next week for part event. RAG and connectors, how to build two. The journey has begun. We look ChatGPT. We look forward to seeing you at each step along forward to seeing you at each step along the way. Until next time, keep building the way. Until next time, keep building shipping and sharing and we'll do the ## [01:01:14 - 01:01:46] shipping and sharing and we'll do the same. See you soon. same. But Greg, how do they get started But Greg, how do they get started building shipping and sharing? Getting building shipping and sharing? Getting started is the hardest part like it was started is the hardest part like it was for you and for me. You can get started for you and for me. You can get started with the AI engineer challenge and you with the AI engineer challenge and you can share it in the build ship share can share it in the build ship share channel on Discord. Links in the channel on Discord. Links in the description. What if they want to description. What if they want to accelerate their ability? Well, we accelerate their ability? Well, we actually have a 10week intensive boot actually have a 10week intensive boot camp where you learn to build, ship, and camp where you learn to build, ship, and share productionready LLM applications share productionready LLM applications every single week. The AI engineering ## [01:01:46 - 01:01:59] every single week. The AI engineering boot camp cohort starting soon. We'll boot camp cohort starting soon. We'll have you building, shipping, and sharing have you building, shipping, and sharing like a legend like a legend in no time. We'll see you in class.